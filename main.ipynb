{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.429316Z",
     "start_time": "2024-06-04T14:24:21.426058Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.models' from '/home/ronin/Dev/notebooks/machinelearningformodeling/supervised/project/scripts/models.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import importlib\n",
    "\n",
    "import scripts.preprocessing as preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "import scripts.models as models\n",
    "import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aec841b882f4ea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.972371Z",
     "start_time": "2024-06-04T14:24:21.961718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.SqueezeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd403b9a5a3434e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:34:04.612770Z",
     "start_time": "2024-06-04T14:34:04.593346Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 13, 13]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 111, 111]        1,792\n",
      "|    └─ReLU: 2-2                         [-1, 64, 111, 111]        --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 55, 55]          --\n",
      "|    └─Fire: 2-4                         [-1, 128, 55, 55]         --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 16, 55, 55]          1,040\n",
      "|    |    └─ReLU: 3-2                    [-1, 16, 55, 55]          --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 64, 55, 55]          1,088\n",
      "|    |    └─ReLU: 3-4                    [-1, 64, 55, 55]          --\n",
      "|    |    └─Conv2d: 3-5                  [-1, 64, 55, 55]          9,280\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 55, 55]          --\n",
      "|    └─Fire: 2-5                         [-1, 128, 55, 55]         --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 16, 55, 55]          2,064\n",
      "|    |    └─ReLU: 3-8                    [-1, 16, 55, 55]          --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 64, 55, 55]          1,088\n",
      "|    |    └─ReLU: 3-10                   [-1, 64, 55, 55]          --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 64, 55, 55]          9,280\n",
      "|    |    └─ReLU: 3-12                   [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 128, 27, 27]         --\n",
      "|    └─Fire: 2-7                         [-1, 256, 27, 27]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 32, 27, 27]          4,128\n",
      "|    |    └─ReLU: 3-14                   [-1, 32, 27, 27]          --\n",
      "|    |    └─Conv2d: 3-15                 [-1, 128, 27, 27]         4,224\n",
      "|    |    └─ReLU: 3-16                   [-1, 128, 27, 27]         --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 128, 27, 27]         36,992\n",
      "|    |    └─ReLU: 3-18                   [-1, 128, 27, 27]         --\n",
      "|    └─Fire: 2-8                         [-1, 256, 27, 27]         --\n",
      "|    |    └─Conv2d: 3-19                 [-1, 32, 27, 27]          8,224\n",
      "|    |    └─ReLU: 3-20                   [-1, 32, 27, 27]          --\n",
      "|    |    └─Conv2d: 3-21                 [-1, 128, 27, 27]         4,224\n",
      "|    |    └─ReLU: 3-22                   [-1, 128, 27, 27]         --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 128, 27, 27]         36,992\n",
      "|    |    └─ReLU: 3-24                   [-1, 128, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-9                    [-1, 256, 13, 13]         --\n",
      "|    └─Fire: 2-10                        [-1, 384, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 48, 13, 13]          12,336\n",
      "|    |    └─ReLU: 3-26                   [-1, 48, 13, 13]          --\n",
      "|    |    └─Conv2d: 3-27                 [-1, 192, 13, 13]         9,408\n",
      "|    |    └─ReLU: 3-28                   [-1, 192, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 192, 13, 13]         83,136\n",
      "|    |    └─ReLU: 3-30                   [-1, 192, 13, 13]         --\n",
      "|    └─Fire: 2-11                        [-1, 384, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-31                 [-1, 48, 13, 13]          18,480\n",
      "|    |    └─ReLU: 3-32                   [-1, 48, 13, 13]          --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 192, 13, 13]         9,408\n",
      "|    |    └─ReLU: 3-34                   [-1, 192, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-35                 [-1, 192, 13, 13]         83,136\n",
      "|    |    └─ReLU: 3-36                   [-1, 192, 13, 13]         --\n",
      "|    └─Fire: 2-12                        [-1, 512, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-37                 [-1, 64, 13, 13]          24,640\n",
      "|    |    └─ReLU: 3-38                   [-1, 64, 13, 13]          --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 256, 13, 13]         16,640\n",
      "|    |    └─ReLU: 3-40                   [-1, 256, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-41                 [-1, 256, 13, 13]         147,712\n",
      "|    |    └─ReLU: 3-42                   [-1, 256, 13, 13]         --\n",
      "|    └─Fire: 2-13                        [-1, 512, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-43                 [-1, 64, 13, 13]          32,832\n",
      "|    |    └─ReLU: 3-44                   [-1, 64, 13, 13]          --\n",
      "|    |    └─Conv2d: 3-45                 [-1, 256, 13, 13]         16,640\n",
      "|    |    └─ReLU: 3-46                   [-1, 256, 13, 13]         --\n",
      "|    |    └─Conv2d: 3-47                 [-1, 256, 13, 13]         147,712\n",
      "|    |    └─ReLU: 3-48                   [-1, 256, 13, 13]         --\n",
      "├─Sequential: 1-2                        [-1, 251, 1, 1]           --\n",
      "|    └─Dropout: 2-14                     [-1, 512, 13, 13]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 251, 13, 13]         128,763\n",
      "|    └─ReLU: 2-16                        [-1, 251, 13, 13]         --\n",
      "|    └─AdaptiveAvgPool2d: 2-17           [-1, 251, 1, 1]           --\n",
      "==========================================================================================\n",
      "Total params: 851,259\n",
      "Trainable params: 851,259\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 285.91\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 18.79\n",
      "Params size (MB): 3.25\n",
      "Estimated Total Size (MB): 22.61\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 224, 224));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e14ecb8153d3b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:14.275625Z",
     "start_time": "2024-06-03T16:30:54.879615Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating data/train\n",
      "Populating data/test\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "#folder_structure = preprocessing.create_dataset()\n",
    "# transform it in a dataframe and list the number of images per class in the folders\n",
    "a = pd.DataFrame([(k, len(v)) for k,v in folder_structure[0].items()], \n",
    "                    columns=['class', 'count'])\n",
    "b = pd.DataFrame([(k, len(v)) for k,v in folder_structure[1].items()], \n",
    "                    columns=['class', 'count'])\n",
    "image_counts = pd.merge(a, \n",
    "                        b, \n",
    "                        on='class', \n",
    "                        how='outer', \n",
    "                        suffixes=('_train', '_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc827c60ede55707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:32.731631Z",
     "start_time": "2024-06-03T16:31:32.724127Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count_train</th>\n",
       "      <th>count_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dolmas</td>\n",
       "      <td>546</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coquilles_saint_jacques</td>\n",
       "      <td>518</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veal_cordon_bleu</td>\n",
       "      <td>277</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shirred_egg</td>\n",
       "      <td>440</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barbecued_wing</td>\n",
       "      <td>602</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     class  count_train  count_test\n",
       "0                   dolmas          546          42\n",
       "1  coquilles_saint_jacques          518          52\n",
       "2         veal_cordon_bleu          277          23\n",
       "3              shirred_egg          440          42\n",
       "4           barbecued_wing          602          34"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0f834241754535d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:34.075806Z",
     "start_time": "2024-06-03T16:31:34.072217Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class          marble_cake\n",
       "count_train             34\n",
       "count_test              49\n",
       "Name: 120, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_counts.loc[np.argmin(image_counts['count_train']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "beb3e757ecebab77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:33:42.664214Z",
     "start_time": "2024-06-03T16:33:42.030197Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing.create_validation(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1979fcf16872184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:08:44.782398Z",
     "start_time": "2024-06-03T17:08:44.644528Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # resize \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize pixel values\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "trainset = torchvision.datasets.ImageFolder(root='data/train', transform=transform)\n",
    "\n",
    "# Create data loader for training data with batch size 4 and shuffling\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root='data/val', transform=transform)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='data/test', transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab488f0446a04bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:06:11.210169Z",
     "start_time": "2024-06-03T17:06:11.207247Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40322ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b34a42cc8cb5f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:23:52.036996Z",
     "start_time": "2024-06-03T17:20:54.527188Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 14810/14810 [24:23<00:00, 10.12batch/s, loss=5.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 5.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.1526, Validation Accuracy: 3.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 14810/14810 [24:28<00:00, 10.09batch/s, loss=5.05]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 5.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.9290, Validation Accuracy: 5.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 14810/14810 [21:57<00:00, 11.24batch/s, loss=4.87]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 4.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.7826, Validation Accuracy: 7.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 14810/14810 [23:40<00:00, 10.43batch/s, loss=4.74]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 4.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.6470, Validation Accuracy: 9.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 14810/14810 [22:02<00:00, 11.20batch/s, loss=4.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 4.6307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.6337, Validation Accuracy: 9.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 14810/14810 [22:03<00:00, 11.19batch/s, loss=4.52]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 4.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4446, Validation Accuracy: 11.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 14810/14810 [22:03<00:00, 11.19batch/s, loss=4.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 4.4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.3907, Validation Accuracy: 12.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 14810/14810 [21:56<00:00, 11.25batch/s, loss=4.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 4.3449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.2601, Validation Accuracy: 14.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 14810/14810 [22:01<00:00, 11.21batch/s, loss=4.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 4.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.1684, Validation Accuracy: 15.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 14810/14810 [22:04<00:00, 11.19batch/s, loss=4.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 4.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.0651, Validation Accuracy: 16.89%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log model parameters\n",
    "mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "mlflow.log_param(\"learning_rate\", 0.001)\n",
    "mlflow.log_param(\"batch_size\", 32)\n",
    "mlflow.log_param(\"num_epochs\", 10)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_loader_tqdm = tqdm.tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", \n",
    "                             unit=\"batch\")\n",
    "\n",
    "    for inputs, labels in train_loader_tqdm:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        train_loader_tqdm.set_postfix(loss=running_loss / len(trainloader))\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "    mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "\n",
    "    # Validation loop (optional)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Log validation loss and accuracy\n",
    "    mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "\n",
    "# Log the model\n",
    "mlflow.pytorch.log_model(model, \"squeezenet_model\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735ad55b2d6a7285",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## parametrized training loop\n",
    "def train_model(model, model_name, trainloader, valloader, criterion, optimizer, scheduler, num_epochs=10, device='cpu'):\n",
    "    mlflow.start_run(run_name=model_name)\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"optimizer\", optimizer.__class__.__name__)\n",
    "    mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "    mlflow.log_param(\"batch_size\", trainloader.batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        train_loader_tqdm = tqdm.tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "        for inputs, labels in train_loader_tqdm:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            train_loader_tqdm.set_postfix(loss=running_loss / len(trainloader))\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        scheduler.step()\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "\n",
    "        # Validation loop (optional)\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(valloader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        # Log validation loss and accuracy\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.pytorch.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "    # End the MLflow run\n",
    "    mlflow.end_run()\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "# model = ...  # Your model definition\n",
    "# trainloader = ...  # Your training data loader\n",
    "# valloader = ...  # Your validation data loader\n",
    "# criterion = ...  # Your loss function\n",
    "# optimizer = ...  # Your optimizer\n",
    "# scheduler = ...  # Your learning rate scheduler\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# train_model(model, \"squeezenet\", trainloader, valloader, criterion, optimizer, scheduler, num_epochs=10, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd9a576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 14810/14810 [21:25<00:00, 11.52batch/s, loss=5.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 5.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.6158, Validation Accuracy: 0.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 14810/14810 [21:59<00:00, 11.23batch/s, loss=5.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 5.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.6157, Validation Accuracy: 0.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  39%|███▉      | 5845/14810 [09:11<14:05, 10.60batch/s, loss=2.21]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_from_scratch \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSqueezeNet()\n\u001b[1;32m      6\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mend_run()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_from_scratch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnetFromScratch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, trainloader, valloader, criterion, optimizer, scheduler, num_epochs, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_from_scratch = models.SqueezeNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "mlflow.end_run()\n",
    "train_model(model_from_scratch,\n",
    "            \"netFromScratch\", \n",
    "            trainloader, \n",
    "            valloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            scheduler,\n",
    "            num_epochs=10, \n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68052995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 14810/14810 [22:05<00:00, 11.18batch/s, loss=5.55]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 5.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.5522, Validation Accuracy: 0.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|██████████| 14810/14810 [21:32<00:00, 11.46batch/s, loss=5.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Loss: 5.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.5522, Validation Accuracy: 0.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|██████████| 14810/14810 [21:28<00:00, 11.50batch/s, loss=5.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Loss: 5.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.5522, Validation Accuracy: 0.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 14810/14810 [21:28<00:00, 11.49batch/s, loss=5.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Loss: 5.5478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.5522, Validation Accuracy: 0.39%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "#mlflow.end_run()\n",
    "model = models.SqueezeNet()\n",
    "model.load_state_dict(torch.load('netFromSSL.pth'))\n",
    "train_model(model,\n",
    "            \"netFromSSL\",\n",
    "            trainloader,\n",
    "            valloader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            num_epochs=4,\n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80664df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best hyperparameters from github non provato\n",
    "\n",
    "# transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'path_to_foodx251_dataset'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "model.classifier[1] = nn.Conv2d(512, len(class_names), kernel_size=(1,1), stride=(1,1))\n",
    "model.num_classes = len(class_names)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders['val']:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= dataset_sizes['val']\n",
    "        val_accuracy = correct / total\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
