{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shbM3zJAuPI9"
      },
      "source": [
        "In this lab you will do the following steps in order:\n",
        "\n",
        "1. What is [SSL](https://docs.google.com/presentation/d/17vkcwjBdyFAy3y9ZYphuV28kIqDtGCW4zUWXgfL54sU/edit?usp=share_link) (Self Supervised Learning).\n",
        "2. Train a CNN using a SSL (image rotation prediction) and perform classification on CIFAR10\n",
        "3. Evaluate the trained model and show the nearest neighbors in the latent space\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nGf18WShCSa"
      },
      "outputs": [],
      "source": [
        "!pip install warmup_scheduler\n",
        "import argparse\n",
        "import os\n",
        "import os.path as osp\n",
        "import time\n",
        "import shutil\n",
        "from warmup_scheduler import GradualWarmupScheduler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjZHAGOVifaG"
      },
      "source": [
        "2. Network definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1go3xqczigxj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class RotationPrediction(nn.Module):\n",
        "    \"\"\"\n",
        "      This class defines a module for predicting image rotation.\n",
        "\n",
        "      It takes images as input and outputs a dictionary containing the loss\n",
        "      and accuracy, as well as the latent features of the images. The class\n",
        "      also provides a method for encoding images into their latent features.\n",
        "\n",
        "      Attributes:\n",
        "          metrics (list): List of metrics to track during training,\n",
        "              containing 'Loss' and 'Acc1' by default.\n",
        "          metrics_fmt (list): List of formatting strings for the metrics.\n",
        "          model (nn.Module): The underlying neural network for feature extraction.\n",
        "          latent_dim (int): Dimensionality of the latent features.\n",
        "          feat_layer (str): Name of the layer in the model that outputs the\n",
        "              features to be used for classification.\n",
        "          n_classes (int): Number of rotation classes (typically 4 for 0, 90, 180, 270 degrees).\n",
        "      \"\"\"\n",
        "    metrics = ['Loss', 'Acc1']\n",
        "    metrics_fmt = [':.4e', ':6.2f']\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.model = NetworkInNetwork()\n",
        "        self.latent_dim = 192 * 8 * 8\n",
        "        self.feat_layer = 'conv2'\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def construct_classifier(self):\n",
        "        classifier = nn.Sequential(\n",
        "            nn.BatchNorm1d(self.latent_dim, affine=False),\n",
        "            nn.Linear(self.latent_dim, self.n_classes)\n",
        "        )\n",
        "        return classifier\n",
        "\n",
        "    def forward(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "        images, targets = self._preprocess(images)\n",
        "        targets = targets.to(images.get_device())\n",
        "\n",
        "        logits, zs = self.model(images, out_feat_keys=['classifier', self.feat_layer])\n",
        "        # print(logits.shape, zs.shape)\n",
        "        loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        correct = pred.eq(targets).float().sum()\n",
        "        acc = correct / targets.shape[0] * 100.\n",
        "\n",
        "        zs = zs[:batch_size]\n",
        "        zs = zs.flatten(start_dim=1)\n",
        "\n",
        "        return dict(Loss=loss, Acc1=acc), zs[:batch_size]\n",
        "\n",
        "    def encode(self, images, flatten=True):\n",
        "        zs = self.model(images, out_feat_keys=(self.feat_layer,))\n",
        "        return zs.flatten(start_dim=1)\n",
        "\n",
        "    def _preprocess(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "        images_90 = torch.flip(images.transpose(2, 3), (2,))\n",
        "        images_180 = torch.flip(images, (2, 3))\n",
        "        images_270 = torch.flip(images, (2,)).transpose(2, 3)\n",
        "        images_batch = torch.cat((images, images_90, images_180, images_270), dim=0)\n",
        "        targets = torch.arange(4).long().repeat(batch_size)\n",
        "        targets = targets.view(batch_size, 4).transpose(0, 1)\n",
        "        targets = targets.contiguous().view(-1)\n",
        "        return images_batch, targets\n",
        "\n",
        "\n",
        "\n",
        "# Code borrowed from https://github.com/gidariss/FeatureLearningRotNet\n",
        "\n",
        "# NetworkInNetwork\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        padding = (kernel_size-1) // 2\n",
        "        self.layers = nn.Sequential()\n",
        "        self.layers.add_module('Conv', nn.Conv2d(in_planes, out_planes,\n",
        "            kernel_size=kernel_size, stride=1, padding=padding, bias=False))\n",
        "        self.layers.add_module('BatchNorm', nn.BatchNorm2d(out_planes))\n",
        "        self.layers.add_module('ReLU',      nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class GlobalAveragePooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalAveragePooling, self).__init__()\n",
        "\n",
        "    def forward(self, feat):\n",
        "        num_channels = feat.size(1)\n",
        "        return F.avg_pool2d(feat, (feat.size(2), feat.size(3))).view(-1, num_channels)\n",
        "\n",
        "\n",
        "class NetworkInNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines a convolutional neural network architecture\n",
        "    specifically designed for image classification.\n",
        "\n",
        "    The network consists of several stages, each containing multiple\n",
        "    convolutional blocks. Each block applies a series of convolutions\n",
        "    and (optionally) pooling operations. The network also includes\n",
        "    global average pooling and a final linear layer for classification.\n",
        "\n",
        "    The network can be configured with a variable number of stages\n",
        "    and the option to use average pooling after the third stage.\n",
        "\n",
        "    Attributes:\n",
        "        num_classes (int): Number of output classes (typically 4 for rotation prediction).\n",
        "        num_inchannels (int): Number of input channels (typically 3 for RGB images).\n",
        "        num_stages (int): Number of stages in the network architecture.\n",
        "        use_avg_on_conv3 (bool): Whether to use average pooling after the third stage.\n",
        "        _feature_blocks (nn.ModuleList): List of modules representing the network stages.\n",
        "        all_feat_names (list): List of names corresponding to each feature output.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(NetworkInNetwork, self).__init__()\n",
        "\n",
        "        num_classes = 4\n",
        "        num_inchannels = 3\n",
        "        num_stages = 4\n",
        "        use_avg_on_conv3 = False\n",
        "\n",
        "\n",
        "        nChannels  = 192\n",
        "        nChannels2 = 160\n",
        "        nChannels3 = 96\n",
        "\n",
        "        blocks = [nn.Sequential() for i in range(num_stages)]\n",
        "        # 1st block\n",
        "        blocks[0].add_module('Block1_ConvB1', BasicBlock(num_inchannels, nChannels, 5))\n",
        "        blocks[0].add_module('Block1_ConvB2', BasicBlock(nChannels,  nChannels2, 1))\n",
        "        blocks[0].add_module('Block1_ConvB3', BasicBlock(nChannels2, nChannels3, 1))\n",
        "        blocks[0].add_module('Block1_MaxPool', nn.MaxPool2d(kernel_size=3,stride=2,padding=1))\n",
        "\n",
        "        # 2nd block\n",
        "        blocks[1].add_module('Block2_ConvB1',  BasicBlock(nChannels3, nChannels, 5))\n",
        "        blocks[1].add_module('Block2_ConvB2',  BasicBlock(nChannels,  nChannels, 1))\n",
        "        blocks[1].add_module('Block2_ConvB3',  BasicBlock(nChannels,  nChannels, 1))\n",
        "        blocks[1].add_module('Block2_AvgPool', nn.AvgPool2d(kernel_size=3,stride=2,padding=1))\n",
        "\n",
        "        # 3rd block\n",
        "        blocks[2].add_module('Block3_ConvB1',  BasicBlock(nChannels, nChannels, 3))\n",
        "        blocks[2].add_module('Block3_ConvB2',  BasicBlock(nChannels, nChannels, 1))\n",
        "        blocks[2].add_module('Block3_ConvB3',  BasicBlock(nChannels, nChannels, 1))\n",
        "\n",
        "        if num_stages > 3 and use_avg_on_conv3:\n",
        "            blocks[2].add_module('Block3_AvgPool', nn.AvgPool2d(kernel_size=3,stride=2,padding=1))\n",
        "        for s in range(3, num_stages):\n",
        "            blocks[s].add_module('Block'+str(s+1)+'_ConvB1',  BasicBlock(nChannels, nChannels, 3))\n",
        "            blocks[s].add_module('Block'+str(s+1)+'_ConvB2',  BasicBlock(nChannels, nChannels, 1))\n",
        "            blocks[s].add_module('Block'+str(s+1)+'_ConvB3',  BasicBlock(nChannels, nChannels, 1))\n",
        "\n",
        "        # global average pooling and classifier\n",
        "        blocks.append(nn.Sequential())\n",
        "        blocks[-1].add_module('GlobalAveragePooling',  GlobalAveragePooling())\n",
        "        blocks[-1].add_module('Classifier', nn.Linear(nChannels, num_classes))\n",
        "\n",
        "        self._feature_blocks = nn.ModuleList(blocks)\n",
        "        self.all_feat_names = ['conv'+str(s+1) for s in range(num_stages)] + ['classifier',]\n",
        "        # print(self.all_feat_names)\n",
        "        assert(len(self.all_feat_names) == len(self._feature_blocks))\n",
        "\n",
        "    def _parse_out_keys_arg(self, out_feat_keys):\n",
        "\n",
        "        # By default return the features of the last layer / module.\n",
        "        out_feat_keys = [self.all_feat_names[-1],] if out_feat_keys is None else out_feat_keys\n",
        "\n",
        "        if len(out_feat_keys) == 0:\n",
        "            raise ValueError('Empty list of output feature keys.')\n",
        "        for f, key in enumerate(out_feat_keys):\n",
        "            if key not in self.all_feat_names:\n",
        "                raise ValueError('Feature with name {0} does not exist. Existing features: {1}.'.format(key, self.all_feat_names))\n",
        "            elif key in out_feat_keys[:f]:\n",
        "                raise ValueError('Duplicate output feature key: {0}.'.format(key))\n",
        "\n",
        "        # Find the highest output feature in `out_feat_keys\n",
        "        max_out_feat = max([self.all_feat_names.index(key) for key in out_feat_keys])\n",
        "\n",
        "        return out_feat_keys, max_out_feat\n",
        "\n",
        "    def forward(self, x, out_feat_keys=None):\n",
        "        \"\"\"Forward an image `x` through the network and return the asked output features.\n",
        "        Args:\n",
        "          x: input image.\n",
        "          out_feat_keys: a list/tuple with the feature names of the features\n",
        "                that the function should return. By default the last feature of\n",
        "                the network is returned.\n",
        "        Return:\n",
        "            out_feats: If multiple output features were asked then `out_feats`\n",
        "                is a list with the asked output features placed in the same\n",
        "                order as in `out_feat_keys`. If a single output feature was\n",
        "                asked then `out_feats` is that output feature (and not a list).\n",
        "        \"\"\"\n",
        "        out_feat_keys, max_out_feat = self._parse_out_keys_arg(out_feat_keys)\n",
        "        out_feats = [None] * len(out_feat_keys)\n",
        "\n",
        "        feat = x\n",
        "        for f in range(max_out_feat+1):\n",
        "            feat = self._feature_blocks[f](feat)\n",
        "            key = self.all_feat_names[f]\n",
        "            if key in out_feat_keys:\n",
        "                out_feats[out_feat_keys.index(key)] = feat\n",
        "\n",
        "        out_feats = out_feats[0] if len(out_feats)==1 else out_feats\n",
        "        return out_feats\n",
        "\n",
        "\n",
        "    def weight_initialization(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m.weight.requires_grad:\n",
        "                    n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                if m.weight.requires_grad:\n",
        "                    m.weight.data.fill_(1)\n",
        "                if m.bias.requires_grad:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                if m.bias.requires_grad:\n",
        "                    m.bias.data.zero_()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzbtYo1FhrQr"
      },
      "source": [
        "Utility functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZPyNaMlhqql"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import math\n",
        "import pickle\n",
        "from collections import OrderedDict, Counter\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def unnormalize(images):\n",
        "    mu = [0.4914, 0.4822, 0.4465]\n",
        "    stddev = [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "\n",
        "    mu = torch.FloatTensor(mu).view(1, 3, 1, 1)\n",
        "    stddev = torch.FloatTensor(stddev).view(1, 3, 1, 1)\n",
        "    return images * stddev + mu\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    This class computes and stores the average and current value of a metric.\n",
        "\n",
        "    It can be used to track various metrics during training or evaluation,\n",
        "    such as loss, accuracy, etc. It provides methods to reset the meter,\n",
        "    update it with new values, and retrieve the current and average values.\n",
        "\n",
        "    Attributes:\n",
        "        name (str): Name of the metric being tracked.\n",
        "        fmt (str): Format string for printing the value (default: ':f').\n",
        "        val (float): Current value of the metric.\n",
        "        avg (float): Average value of the metric computed over updates.\n",
        "        sum (float): Running sum of the metric values.\n",
        "        count (int): Number of updates performed.\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    \"\"\"\n",
        "    Displays progress information during training or evaluation.\n",
        "\n",
        "    This class helps to print informative messages during training or evaluation.\n",
        "    It takes the total number of batches and a list of AverageMeter objects\n",
        "    as input, and then displays the current batch number, the values of the\n",
        "    provided meters, and any additional prefix text.\n",
        "\n",
        "    Attributes:\n",
        "        batch_fmtstr (str): Format string for displaying the current batch number.\n",
        "        meters (list): List of AverageMeter objects to track.\n",
        "        prefix (str): Optional prefix string to add before the output message.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhN-Ou86htnm"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmVmVJ8pht6P"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def get_transform(train=True):\n",
        "  if train:\n",
        "      transform = transforms.Compose([\n",
        "          transforms.RandomCrop(32, padding=4),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "      ])\n",
        "  else:\n",
        "      transform = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "      ])\n",
        "  return transform\n",
        "\n",
        "\n",
        "def get_datasets():\n",
        "\n",
        "  train_dset = datasets.CIFAR10('data', train=True,\n",
        "                                transform=get_transform(train=True),\n",
        "                                download=True)\n",
        "  test_dset = datasets.CIFAR10('data', train=False,\n",
        "                                transform=get_transform(train=False),\n",
        "                                download=True)\n",
        "  return train_dset, test_dset, len(train_dset.classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDuhT9fxjBaZ"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQkrWzHvjCpe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(train_loader, model, linear_classifier, optimizer,\n",
        "          optimizer_linear, epoch):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    top1 = AverageMeter('LinearAcc@1', ':6.2f')\n",
        "    top5 = AverageMeter('LinearAcc@5', ':6.2f')\n",
        "    avg_meters = {k: AverageMeter(k, fmt)\n",
        "                  for k, fmt in zip(metrics, metrics_fmt)}\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, top1, top5] + list(avg_meters.values()),\n",
        "        prefix=\"Epoch: [{}]\".format(epoch)\n",
        "    )\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    linear_classifier.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        # compute loss\n",
        "        if isinstance(images, (tuple, list)):\n",
        "            # Special case for SimCLR which returns a tuple of 2 image batches\n",
        "            bs = images[0].shape[0]\n",
        "            images = [x.cuda()\n",
        "                      for x in images]\n",
        "        else:\n",
        "            bs = images.shape[0]\n",
        "            images = images.cuda()\n",
        "        target = target.cuda()\n",
        "        out, zs = model(images)\n",
        "        zs = zs.detach()\n",
        "        for k, v in out.items():\n",
        "            avg_meters[k].update(v.item(), bs)\n",
        "\n",
        "        # compute gradient and optimizer step for ssl task\n",
        "        optimizer.zero_grad()\n",
        "        out['Loss'].backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # compute gradient and optimizer step for classifier\n",
        "        logits = linear_classifier(zs)\n",
        "        loss = F.cross_entropy(logits, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "        top1.update(acc1[0], bs)\n",
        "        top5.update(acc5[0], bs)\n",
        "\n",
        "        optimizer_linear.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_linear.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % log_interval == 0:\n",
        "            progress.display(i)\n",
        "\n",
        "\n",
        "def validate(val_loader, model, linear_classifier):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    top1 = AverageMeter('LinearAcc@1', ':6.2f')\n",
        "    top5 = AverageMeter('LinearAcc@5', ':6.2f')\n",
        "    avg_meters = {k: AverageMeter(k, fmt)\n",
        "                  for k, fmt in zip(metrics, metrics_fmt)}\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader),\n",
        "        [batch_time, data_time, top1, top5] + list(avg_meters.values()),\n",
        "        prefix=\"Test: \"\n",
        "    )\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    linear_classifier.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            # compute and measure loss\n",
        "            if isinstance(images, (tuple, list)):\n",
        "                # Special case for SimCLR which returns a tuple of 2 image batches\n",
        "                bs = images[0].shape[0]\n",
        "                images = [x.cuda()\n",
        "                        for x in images]\n",
        "            else:\n",
        "                bs = images.shape[0]\n",
        "                images = images.cuda()\n",
        "            target = target.cuda()\n",
        "            out, zs = model(images)\n",
        "            for k, v in out.items():\n",
        "                avg_meters[k].update(v.item(), bs)\n",
        "\n",
        "            logits = linear_classifier(zs)\n",
        "            acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "            top1.update(acc1[0], bs)\n",
        "            top5.update(acc5[0], bs)\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % log_interval == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "    data = torch.FloatTensor([avg_meters['Loss'].avg, top1.avg, top5.avg] + [v.avg for v in avg_meters.values()])\n",
        "\n",
        "    print_str = f' * LinearAcc@1 {data[1]:.3f} LinearAcc@5 {data[2]:.3f}'\n",
        "    for i, (k, v) in enumerate(avg_meters.items()):\n",
        "        print_str += f' {k} {data[i+3]:.3f}'\n",
        "    print(print_str)\n",
        "\n",
        "    return data[0], data[1]\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    filename = osp.join(output_dir, filename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, osp.join(output_dir, 'model_best.pth.tar'))\n",
        "\n",
        "batch_size=128\n",
        "epochs=5\n",
        "optimizer='sgd' #'sgd|lars|adam (default: sgd)')\n",
        "lr=0.01\n",
        "momentum=0.9\n",
        "weight_decay=5e-4\n",
        "warmup_epochs=0 #'# of warmup epochs. If > 0, then the scheduler warmups from lr * batch_size / 256.')\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0.0\n",
        "\n",
        "log_interval=10\n",
        "\n",
        "output_dir = 'results'\n",
        "if not osp.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "total_batch_size = batch_size\n",
        "\n",
        "train_dataset, val_dataset, n_classes = get_datasets()\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, num_workers=2,\n",
        "    pin_memory=True, drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, num_workers=2,\n",
        "    pin_memory=True, drop_last=True\n",
        ")\n",
        "\n",
        "model = RotationPrediction(n_classes)\n",
        "metrics = model.metrics\n",
        "metrics_fmt = model.metrics_fmt\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "model.cuda()\n",
        "\n",
        "linear_classifier = model.construct_classifier().cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum,\n",
        "                            weight_decay=weight_decay, nesterov=True)\n",
        "optimizer_linear = torch.optim.SGD(linear_classifier.parameters(), lr=lr,\n",
        "                                    momentum=momentum, nesterov=True)\n",
        "\n",
        "\n",
        "# Minimize SSL task loss, maximize linear classification accuracy\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, epochs, 0, -1)\n",
        "scheduler_linear = lr_scheduler.CosineAnnealingLR(optimizer_linear, epochs, 0, -1)\n",
        "if warmup_epochs > 0:\n",
        "    scheduler = GradualWarmupScheduler(optimizer, multiplier=total_batch_size / 256.,\n",
        "                                        total_epoch=warmup_epochs, after_scheduler=scheduler)\n",
        "    scheduler_linear = GradualWarmupScheduler(optimizer, multiplier=total_batch_size / 256.,\n",
        "                                              total_epoch=warmup_epochs,\n",
        "                                              after_scheduler=scheduler_linear)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train(train_loader, model, linear_classifier,\n",
        "          optimizer, optimizer_linear, epoch)\n",
        "\n",
        "    val_loss, val_acc = validate(val_loader, model, linear_classifier)\n",
        "\n",
        "    scheduler.step()\n",
        "    scheduler_linear.step()\n",
        "\n",
        "    is_best = val_loss < best_loss\n",
        "    best_loss = min(val_loss, best_loss)\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'state_dict_linear': linear_classifier.state_dict(),\n",
        "        'optimizer_linear': optimizer_linear.state_dict(),\n",
        "        'schedular_linear': scheduler_linear.state_dict(),\n",
        "        'best_loss': best_loss,\n",
        "        'best_acc': val_acc\n",
        "    }, is_best)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfF9dcIzt9lE"
      },
      "source": [
        "3. Evaluation Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8CI46ANt-ub"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def load_model_and_data():\n",
        "    train_dset, test_dset, n_classes = get_datasets()\n",
        "    train_loader = data.DataLoader(train_dset, batch_size=128, num_workers=2,\n",
        "                                   pin_memory=True, shuffle=True)\n",
        "    test_loader = data.DataLoader(test_dset, batch_size=128, num_workers=2,\n",
        "                                  pin_memory=True, shuffle=True)\n",
        "\n",
        "    ckpt_pth = osp.join('results', 'model_best.pth.tar')\n",
        "    ckpt = torch.load(ckpt_pth, map_location='cpu')\n",
        "\n",
        "    model = RotationPrediction(n_classes)\n",
        "\n",
        "    model.load_state_dict(ckpt['state_dict'])\n",
        "\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    linear_classifier = model.construct_classifier()\n",
        "    linear_classifier.load_state_dict(ckpt['state_dict_linear'])\n",
        "\n",
        "    linear_classifier.cuda()\n",
        "    linear_classifier.eval()\n",
        "\n",
        "    return model, linear_classifier, train_loader, test_loader\n",
        "\n",
        "\n",
        "def evaluate_accuracy(model, linear_classifier, train_loader, test_loader):\n",
        "    train_acc1, train_acc5 = evaluate_classifier(model, linear_classifier, train_loader)\n",
        "    test_acc1, test_acc5 = evaluate_classifier(model, linear_classifier, test_loader)\n",
        "\n",
        "    print('Train Set')\n",
        "    print(f'Top 1 Accuracy: {train_acc1}, Top 5 Accuracy: {train_acc5}\\n')\n",
        "    print('Test Set')\n",
        "    print(f'Top 1 Accuracy: {test_acc1}, Top 5 Accuracy: {test_acc5}\\n')\n",
        "\n",
        "\n",
        "def evaluate_classifier(model, linear_classifier, loader):\n",
        "    correct1, correct5 = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, target in loader:\n",
        "            images = images_to_cuda(images)\n",
        "            target = target.cuda(non_blocking=True)\n",
        "            out, zs = model(images)\n",
        "\n",
        "            logits = linear_classifier(zs)\n",
        "            acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "\n",
        "            correct1 += acc1.item() * logits.shape[0]\n",
        "            correct5 += acc5.item() * logits.shape[0]\n",
        "    total = len(loader.dataset)\n",
        "\n",
        "    return correct1 / total, correct5 / total\n",
        "\n",
        "\n",
        "def display_nearest_neighbors(model, loader, n_examples=4, k=16):\n",
        "    \"\"\"\n",
        "    This function visualizes the nearest neighbors of a set of reference images\n",
        "    in the latent space of a rotation prediction model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The rotation prediction model.\n",
        "        loader (torch.utils.data.DataLoader): The data loader containing the images.\n",
        "        n_examples (int, optional): The number of reference images to use. Defaults to 4.\n",
        "        k (int, optional): The number of nearest neighbors to find for each reference image. Defaults to 16.\n",
        "\n",
        "    Prints and displays images using matplotlib:\n",
        "        - Each reference image.\n",
        "        - A grid of nearest neighbors for each reference image.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        all_images, all_zs = [], []\n",
        "        for i, (images, _) in enumerate(loader):\n",
        "            images = images_to_cuda(images)\n",
        "\n",
        "            zs = model.encode(images)\n",
        "\n",
        "            images = images.cpu()\n",
        "            zs = zs.cpu()\n",
        "\n",
        "            if i == 0:\n",
        "                ref_zs = zs[:n_examples]\n",
        "                ref_images = images[:n_examples]\n",
        "                all_zs.append(zs[n_examples:])\n",
        "                all_images.append(images[n_examples:])\n",
        "            else:\n",
        "                all_zs.append(zs)\n",
        "                all_images.append(images)\n",
        "        all_images = torch.cat(all_images, dim=0)\n",
        "        all_zs = torch.cat(all_zs, dim=0)\n",
        "\n",
        "        aa = (ref_zs ** 2).sum(dim=1).unsqueeze(dim=1)\n",
        "        ab = torch.matmul(ref_zs, all_zs.t())\n",
        "        bb = (all_zs ** 2).sum(dim=1).unsqueeze(dim=0)\n",
        "        dists = torch.sqrt(aa - 2 * ab + bb)\n",
        "\n",
        "        idxs = torch.topk(dists, k, dim=1, largest=False)[1]\n",
        "        sel_images = torch.index_select(all_images, 0, idxs.view(-1))\n",
        "        sel_images = unnormalize(sel_images.cpu())\n",
        "        sel_images = sel_images.view(n_examples, k, *sel_images.shape[-3:])\n",
        "\n",
        "        ref_images = unnormalize(ref_images.cpu())\n",
        "        ref_images = (ref_images.permute(0, 2, 3, 1) * 255.).numpy().astype('uint8')\n",
        "\n",
        "        for i in range(n_examples):\n",
        "            print(f'Image {i + 1}')\n",
        "            plt.figure()\n",
        "            plt.axis('off')\n",
        "            plt.imshow(ref_images[i])\n",
        "            plt.show()\n",
        "\n",
        "            grid_img = make_grid(sel_images[i], nrow=4)\n",
        "            grid_img = (grid_img.permute(1, 2, 0) * 255.).numpy().astype('uint8')\n",
        "\n",
        "            print(f'Top {k} Nearest Neighbors (in latent space)')\n",
        "            plt.figure()\n",
        "            plt.axis('off')\n",
        "            plt.imshow(grid_img)\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "def images_to_cuda(images):\n",
        "    if isinstance(images, (tuple, list)):\n",
        "        images = [x.cuda(non_blocking=True) for x in images]\n",
        "    else:\n",
        "        images = images.cuda(non_blocking=True)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COZCFN75z4x6"
      },
      "source": [
        "### Linear Classification\n",
        "We can use the feature maps in the later convolutional layers of the pretrained model as our learned representation for linear classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XBmqsUWuGYc"
      },
      "outputs": [],
      "source": [
        "# Load the model, a separate linear classifier, training data loader, and testing data loader\n",
        "model, linear_classifier, train_loader, test_loader = load_model_and_data()\n",
        "# Evaluate the model's accuracy on the testing data\n",
        "evaluate_accuracy(model, linear_classifier, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DiA9kai0ncr"
      },
      "source": [
        "### Nearest Neighbors\n",
        "Another way to evaluate our learned representation is to look at nearest neighbors to random encoded images in latent space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sePwukfM0sef"
      },
      "outputs": [],
      "source": [
        "display_nearest_neighbors(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}