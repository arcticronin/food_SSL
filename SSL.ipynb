{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.429316Z",
     "start_time": "2024-06-04T14:24:21.426058Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.models' from '/home/ronin/Dev/notebooks/machinelearningformodeling/supervised/project/scripts/models.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import importlib\n",
    "import scripts.preprocessing as preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "import scripts.models as models\n",
    "import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aec841b882f4ea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.972371Z",
     "start_time": "2024-06-04T14:24:21.961718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.ColorizationSqueezeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd403b9a5a3434e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:34:04.612770Z",
     "start_time": "2024-06-04T14:34:04.593346Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 112, 112]        640\n",
      "|    └─ReLU: 2-2                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 56, 56]          --\n",
      "|    └─Fire: 2-4                         [-1, 128, 56, 56]         --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 16, 56, 56]          1,040\n",
      "|    |    └─ReLU: 3-2                    [-1, 16, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 64, 56, 56]          1,088\n",
      "|    |    └─ReLU: 3-4                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-5                  [-1, 64, 56, 56]          9,280\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
      "|    └─Fire: 2-5                         [-1, 128, 56, 56]         --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 16, 56, 56]          2,064\n",
      "|    |    └─ReLU: 3-8                    [-1, 16, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 64, 56, 56]          1,088\n",
      "|    |    └─ReLU: 3-10                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 64, 56, 56]          9,280\n",
      "|    |    └─ReLU: 3-12                   [-1, 64, 56, 56]          --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 128, 28, 28]         --\n",
      "|    └─Fire: 2-7                         [-1, 256, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 32, 28, 28]          4,128\n",
      "|    |    └─ReLU: 3-14                   [-1, 32, 28, 28]          --\n",
      "|    |    └─Conv2d: 3-15                 [-1, 128, 28, 28]         4,224\n",
      "|    |    └─ReLU: 3-16                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 128, 28, 28]         36,992\n",
      "|    |    └─ReLU: 3-18                   [-1, 128, 28, 28]         --\n",
      "|    └─Fire: 2-8                         [-1, 256, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-19                 [-1, 32, 28, 28]          8,224\n",
      "|    |    └─ReLU: 3-20                   [-1, 32, 28, 28]          --\n",
      "|    |    └─Conv2d: 3-21                 [-1, 128, 28, 28]         4,224\n",
      "|    |    └─ReLU: 3-22                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 128, 28, 28]         36,992\n",
      "|    |    └─ReLU: 3-24                   [-1, 128, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-9                    [-1, 256, 14, 14]         --\n",
      "|    └─Fire: 2-10                        [-1, 384, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 48, 14, 14]          12,336\n",
      "|    |    └─ReLU: 3-26                   [-1, 48, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-27                 [-1, 192, 14, 14]         9,408\n",
      "|    |    └─ReLU: 3-28                   [-1, 192, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 192, 14, 14]         83,136\n",
      "|    |    └─ReLU: 3-30                   [-1, 192, 14, 14]         --\n",
      "|    └─Fire: 2-11                        [-1, 384, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-31                 [-1, 48, 14, 14]          18,480\n",
      "|    |    └─ReLU: 3-32                   [-1, 48, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 192, 14, 14]         9,408\n",
      "|    |    └─ReLU: 3-34                   [-1, 192, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-35                 [-1, 192, 14, 14]         83,136\n",
      "|    |    └─ReLU: 3-36                   [-1, 192, 14, 14]         --\n",
      "|    └─Fire: 2-12                        [-1, 512, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-37                 [-1, 64, 14, 14]          24,640\n",
      "|    |    └─ReLU: 3-38                   [-1, 64, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 256, 14, 14]         16,640\n",
      "|    |    └─ReLU: 3-40                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-41                 [-1, 256, 14, 14]         147,712\n",
      "|    |    └─ReLU: 3-42                   [-1, 256, 14, 14]         --\n",
      "|    └─Fire: 2-13                        [-1, 512, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-43                 [-1, 64, 14, 14]          32,832\n",
      "|    |    └─ReLU: 3-44                   [-1, 64, 14, 14]          --\n",
      "|    |    └─Conv2d: 3-45                 [-1, 256, 14, 14]         16,640\n",
      "|    |    └─ReLU: 3-46                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-47                 [-1, 256, 14, 14]         147,712\n",
      "|    |    └─ReLU: 3-48                   [-1, 256, 14, 14]         --\n",
      "├─Decoder: 1-2                           [-1, 3, 224, 224]         --\n",
      "|    └─Sequential: 2-14                  [-1, 3, 224, 224]         --\n",
      "|    |    └─Conv2d: 3-49                 [-1, 256, 14, 14]         131,328\n",
      "|    |    └─ReLU: 3-50                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Upsample: 3-51               [-1, 256, 28, 28]         --\n",
      "|    |    └─FireDecoder: 3-52            [-1, 128, 28, 28]         90,304\n",
      "|    |    └─Upsample: 3-53               [-1, 128, 56, 56]         --\n",
      "|    |    └─FireDecoder: 3-54            [-1, 64, 56, 56]          22,624\n",
      "|    |    └─Upsample: 3-55               [-1, 64, 112, 112]        --\n",
      "|    |    └─FireDecoder: 3-56            [-1, 32, 112, 112]        5,680\n",
      "|    |    └─Upsample: 3-57               [-1, 32, 224, 224]        --\n",
      "|    |    └─FireDecoder: 3-58            [-1, 16, 224, 224]        1,432\n",
      "|    |    └─Conv2d: 3-59                 [-1, 3, 224, 224]         435\n",
      "|    |    └─Tanh: 3-60                   [-1, 3, 224, 224]         --\n",
      "==========================================================================================\n",
      "Total params: 973,147\n",
      "Trainable params: 973,147\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 604.57\n",
      "==========================================================================================\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 38.23\n",
      "Params size (MB): 3.71\n",
      "Estimated Total Size (MB): 42.14\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (1, 224, 224));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e14ecb8153d3b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:14.275625Z",
     "start_time": "2024-06-03T16:30:54.879615Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        grayscale_image = transforms.functional.rgb_to_grayscale(image, num_output_channels=1)\n",
    "        \n",
    "        return grayscale_image, image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ImageDataset(image_folder='SSL/images', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735ad55b2d6a7285",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133ba8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, num_epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "        mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "        mlflow.log_param(\"batch_size\", dataloader.batch_size)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Use tqdm for the progress bar\n",
    "            progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "            for grayscale, color in progress_bar:\n",
    "                grayscale = grayscale.to(device)\n",
    "                color = color.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(grayscale)\n",
    "                loss = criterion(outputs, color)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * grayscale.size(0)\n",
    "\n",
    "                # Update progress bar with the current loss\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "            mlflow.log_metric(\"loss\", epoch_loss, step=epoch)\n",
    "\n",
    "        # Log the model at the end of the run\n",
    "        mlflow.pytorch.log_model(model, \"colorization_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966408fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 3576/3576 [50:02<00:00,  1.19it/s, loss=0.0124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 3576/3576 [47:20<00:00,  1.26it/s, loss=0.0135] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 3576/3576 [47:12<00:00,  1.26it/s, loss=0.0126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 3576/3576 [47:14<00:00,  1.26it/s, loss=0.0109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 3576/3576 [47:11<00:00,  1.26it/s, loss=0.0134] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train(model, dataloader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada372f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), 'modelSSL.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de762c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mdel from disk\n",
    "model = models.ColorizationSqueezeNet()\n",
    "model.load_state_dict(torch.load('modelSSL.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0120dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adaa9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load netFromSSL from disk\n",
    "# Load the original state dictionary\n",
    "state_dict = torch.load('modelSSL.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f65897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first layer's weights to handle three channels\n",
    "original_weights = state_dict['features.0.weight']  # Shape: [64, 1, 3, 3]\n",
    "\n",
    "# Create a new weight tensor with three channels\n",
    "new_weights = torch.zeros((original_weights.size(0), \n",
    "                           3, \n",
    "                           original_weights.size(2), \n",
    "                           original_weights.size(3)))\n",
    "\n",
    "# Copy the original weights to each of the three channels\n",
    "new_weights[:, 0:1, :, :] = original_weights\n",
    "new_weights[:, 1:2, :, :] = original_weights\n",
    "new_weights[:, 2:3, :, :] = original_weights\n",
    "\n",
    "# Replace the weights in the state dictionary\n",
    "state_dict['features.0.weight'] = new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c9acee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netFromSSL = models.SqueezeNet()\n",
    "\n",
    "# Extract the `features` part of the state dictionary and remove the \"features.\" prefix\n",
    "features_state_dict = {k.replace('features.', ''): v for k, v in state_dict.items() if k.startswith('features.')}\n",
    "\n",
    "# Create the SqueezeNet model with three input channels\n",
    "netFromSSL = models.SqueezeNet()\n",
    "\n",
    "# Load the `features` part of the state dictionary into the new model\n",
    "netFromSSL.features.load_state_dict(features_state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09809451",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netFromSSL.state_dict(), 'netFromSSL.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0d427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
