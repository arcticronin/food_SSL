{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:52:41.109849Z","iopub.status.busy":"2024-06-09T08:52:41.109503Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running locally\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import shutil\n","import importlib\n","import sys\n","\n","# Determine the environment and import preprocessing module accordingly\n","def is_kaggle():\n","    return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n","\n","if is_kaggle():\n","    print(\"Running on Kaggle\")\n","    # Assuming 'preprocessing.py' and other scripts are in '/kaggle/input'\n","    kaggle_input_path = '/kaggle/usr/lib'\n","    sys.path.append(kaggle_input_path)\n","    \n","    import preprocessing_py.preprocessing_py as preprocessing\n","    import models_py.models_py as models\n","    import utils_py.utils_py as utils\n","   \n","    \n","    # Install missing libraries on kaggle\n","    ! pip install torchsummary\n","    ! pip install mlflow\n","else:\n","    print(\"Running locally\")\n","    import scripts.preprocessing as preprocessing\n","    import scripts.models as models\n","    import scripts.utils as utils\n","    \n","    \n","    \n","# Reload the module (if necessary)\n","importlib.reload(preprocessing)\n","importlib.reload(models)\n","importlib.reload(utils)\n","\n","# Other imports\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms\n","import torchsummary\n","import torch.optim as optim\n","\n","import tqdm\n","import mlflow\n","import mlflow.pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#set the correct directory for mlflow tracking\n","#mlflow.set_tracking_uri(\"file:./mlruns\")"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available!  Training on GPU ...\n","cuda:0\n"]}],"source":["device = utils.use_GPU()"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2024-06-04T14:24:21.972371Z","start_time":"2024-06-04T14:24:21.961718Z"},"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["model = models.SqueezeNet()\n","model = model.to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2024-06-04T14:34:04.612770Z","start_time":"2024-06-04T14:34:04.593346Z"},"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 111, 111]           1,792\n","              ReLU-2         [-1, 64, 111, 111]               0\n","         MaxPool2d-3           [-1, 64, 55, 55]               0\n","            Conv2d-4           [-1, 16, 55, 55]           1,040\n","              ReLU-5           [-1, 16, 55, 55]               0\n","            Conv2d-6           [-1, 64, 55, 55]           1,088\n","              ReLU-7           [-1, 64, 55, 55]               0\n","            Conv2d-8           [-1, 64, 55, 55]           9,280\n","              ReLU-9           [-1, 64, 55, 55]               0\n","             Fire-10          [-1, 128, 55, 55]               0\n","           Conv2d-11           [-1, 16, 55, 55]           2,064\n","             ReLU-12           [-1, 16, 55, 55]               0\n","           Conv2d-13           [-1, 64, 55, 55]           1,088\n","             ReLU-14           [-1, 64, 55, 55]               0\n","           Conv2d-15           [-1, 64, 55, 55]           9,280\n","             ReLU-16           [-1, 64, 55, 55]               0\n","             Fire-17          [-1, 128, 55, 55]               0\n","        MaxPool2d-18          [-1, 128, 27, 27]               0\n","           Conv2d-19           [-1, 32, 27, 27]           4,128\n","             ReLU-20           [-1, 32, 27, 27]               0\n","           Conv2d-21          [-1, 128, 27, 27]           4,224\n","             ReLU-22          [-1, 128, 27, 27]               0\n","           Conv2d-23          [-1, 128, 27, 27]          36,992\n","             ReLU-24          [-1, 128, 27, 27]               0\n","             Fire-25          [-1, 256, 27, 27]               0\n","           Conv2d-26           [-1, 32, 27, 27]           8,224\n","             ReLU-27           [-1, 32, 27, 27]               0\n","           Conv2d-28          [-1, 128, 27, 27]           4,224\n","             ReLU-29          [-1, 128, 27, 27]               0\n","           Conv2d-30          [-1, 128, 27, 27]          36,992\n","             ReLU-31          [-1, 128, 27, 27]               0\n","             Fire-32          [-1, 256, 27, 27]               0\n","        MaxPool2d-33          [-1, 256, 13, 13]               0\n","           Conv2d-34           [-1, 48, 13, 13]          12,336\n","             ReLU-35           [-1, 48, 13, 13]               0\n","           Conv2d-36          [-1, 192, 13, 13]           9,408\n","             ReLU-37          [-1, 192, 13, 13]               0\n","           Conv2d-38          [-1, 192, 13, 13]          83,136\n","             ReLU-39          [-1, 192, 13, 13]               0\n","             Fire-40          [-1, 384, 13, 13]               0\n","           Conv2d-41           [-1, 48, 13, 13]          18,480\n","             ReLU-42           [-1, 48, 13, 13]               0\n","           Conv2d-43          [-1, 192, 13, 13]           9,408\n","             ReLU-44          [-1, 192, 13, 13]               0\n","           Conv2d-45          [-1, 192, 13, 13]          83,136\n","             ReLU-46          [-1, 192, 13, 13]               0\n","             Fire-47          [-1, 384, 13, 13]               0\n","           Conv2d-48           [-1, 64, 13, 13]          24,640\n","             ReLU-49           [-1, 64, 13, 13]               0\n","           Conv2d-50          [-1, 256, 13, 13]          16,640\n","             ReLU-51          [-1, 256, 13, 13]               0\n","           Conv2d-52          [-1, 256, 13, 13]         147,712\n","             ReLU-53          [-1, 256, 13, 13]               0\n","             Fire-54          [-1, 512, 13, 13]               0\n","           Conv2d-55           [-1, 64, 13, 13]          32,832\n","             ReLU-56           [-1, 64, 13, 13]               0\n","           Conv2d-57          [-1, 256, 13, 13]          16,640\n","             ReLU-58          [-1, 256, 13, 13]               0\n","           Conv2d-59          [-1, 256, 13, 13]         147,712\n","             ReLU-60          [-1, 256, 13, 13]               0\n","             Fire-61          [-1, 512, 13, 13]               0\n","          Dropout-62          [-1, 512, 13, 13]               0\n","           Conv2d-63          [-1, 251, 13, 13]         128,763\n","             ReLU-64          [-1, 251, 13, 13]               0\n","AdaptiveAvgPool2d-65            [-1, 251, 1, 1]               0\n","================================================================\n","Total params: 851,259\n","Trainable params: 851,259\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 51.83\n","Params size (MB): 3.25\n","Estimated Total Size (MB): 55.65\n","----------------------------------------------------------------\n"]}],"source":["torchsummary.summary(model, (3, 224, 224));"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2024-06-03T16:31:14.275625Z","start_time":"2024-06-03T16:30:54.879615Z"},"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory data/train created\n","Directory data/test created\n"]}],"source":["# Load data\n","if not is_kaggle():\n","\n","    # check if the train folder is  already created\n","    if not os.path.exists('data/train'):\n","        folder_structure = preprocessing.create_dataset()\n","        # transform it in a dataframe and list the number of images per class in the folders\n","        a = pd.DataFrame([(k, len(v)) for k,v in folder_structure[0].items()], \n","                            columns=['class', 'count'])\n","        b = pd.DataFrame([(k, len(v)) for k,v in folder_structure[1].items()], \n","                            columns=['class', 'count'])\n","        image_counts = pd.merge(a, \n","                                b, \n","                                on='class', \n","                                how='outer', \n","                                suffixes=('_train', '_test'))\n","        \n","        \n","        image_counts.loc[np.argmin(image_counts['count_train']),:]\n","        # create a validation set\n","        preprocessing.create_validation(42);"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["if is_kaggle():\n","    im_dir = '/kaggle/input/food-dataset-sl/'\n","else:\n","    im_dir ='.'  "]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'.'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["im_dir"]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2024-06-03T17:08:44.782398Z","start_time":"2024-06-03T17:08:44.644528Z"},"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    # resize \n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    # Normalize pixel values\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","# Load the training dataset\n","trainset = torchvision.datasets.ImageFolder(root=os.path.join(im_dir,'data/train'), transform=transform)\n","\n","# Create data loader for training data with batch size 4 and shuffling\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n","\n","valset = torchvision.datasets.ImageFolder(root=os.path.join(im_dir,'data/val'), transform=transform)\n","\n","valloader = torch.utils.data.DataLoader(valset, batch_size=16, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.ImageFolder(root=os.path.join(im_dir,'data/test'), transform=transform)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["# Define criterion, optimizer and scheduler and other parameters for training\n","opt = \"Adam\"                        # optimizer to be used: [\"Adam\" or \"SGD\"]\n","momentum = 0.9                      # momentum ONLY for SGD optimizer\n","weight_decay = 1e-4                 # weight decay ONLY on Adam optimizer\n","step_size = 7                       # step size for the scheduler\n","gamma = 0.1                         # gamma for the scheduler\n","\n","batch_size = 8                      # batch size\n","num_epochs=10                       # number of epochs\n","patience = 3                        # patience for early stopping\n","criterion =\"CrossEntropyLoss\"       # loss function to be used: [\"CrossEntropyLoss\", \"MSELoss\", \"L1Loss\", \"NLLLoss\"]\n","lr = 5e-5                           # learning rate\n","\n","model_name = \"squeezenet\"           # model name\n","model = models.SqueezeNet()         # model\n","\n","\n","\n","#set the optimizer\n","if opt == \"Adam\":\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","elif opt == \"SGD\":\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","else:\n","    print(\"Invalid optimizer\")\n","\n","#set the criterion\n","if criterion == \"CrossEntropyLoss\":\n","    criterion = nn.CrossEntropyLoss()\n","elif criterion == \"MSELoss\":\n","    criterion = nn.MSELoss()\n","elif criterion == \"L1Loss\":\n","    criterion = nn.L1Loss()\n","elif criterion == \"NLLLoss\":\n","    criterion = nn.NLLLoss()\n","else:\n","    print(\"Invalid criterion\")\n","\n","#set the scheduler\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","# Upload model to correct device\n","model = model.to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["def set_training_parameters(model, model_name, opt, lr, weight_decay, momentum, criterion, step_size, gamma, num_epochs, patience, device):\n","\n","    #set the optimizer\n","    if opt == \"Adam\":\n","        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    elif opt == \"SGD\":\n","        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","    else:\n","        print(\"Invalid optimizer\")\n","\n","    #set the criterion\n","    if criterion == \"CrossEntropyLoss\":\n","        criterion = nn.CrossEntropyLoss()\n","    elif criterion == \"MSELoss\":\n","        criterion = nn.MSELoss()\n","    elif criterion == \"L1Loss\":\n","        criterion = nn.L1Loss()\n","    elif criterion == \"NLLLoss\":\n","        criterion = nn.NLLLoss()\n","    else:\n","        print(\"Invalid criterion\")\n","\n","    #set the scheduler\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","    # Upload model to correct device\n","    model = model.to(device)\n","    \n","    training_parameters = {}\n","    training_parameters['model'] = model\n","    training_parameters['model_name'] = model_name\n","    training_parameters['criterion'] = criterion\n","    training_parameters['optimizer'] = optimizer\n","    training_parameters['scheduler'] = scheduler\n","    training_parameters['num_epochs'] = num_epochs\n","    training_parameters['patience'] = patience\n","    \n","    return training_parameters"]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2024-06-03T17:23:52.036996Z","start_time":"2024-06-03T17:20:54.527188Z"},"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Training function based on above parameters\n","def train_model(model, model_name, trainloader, valloader, criterion, optimizer, scheduler, num_epochs=10, patience=3 ):\n","\n","    mlflow.start_run(run_name=model_name)\n","\n","    # Log model parameters\n","    mlflow.log_param(\"optimizer\", opt)\n","    mlflow.log_param(\"learning_rate\", lr)\n","    mlflow.log_param(\"batch_size\", batch_size)\n","    mlflow.log_param(\"num_epochs\", num_epochs)\n","    mlflow.log_param(\"momentum\", momentum)\n","    mlflow.log_param(\"weight_decay\", weight_decay)\n","    mlflow.log_param(\"step_size\", step_size)\n","    mlflow.log_param(\"gamma\", gamma)\n","    mlflow.log_param(\"patience\", patience)\n","\n","\n","    patience_counter = 0\n","    best_model = None\n","    best_loss = np.inf\n","        \n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","        running_loss = 0.0\n","        train_loader_tqdm = tqdm.tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", \n","                                unit=\"batch\")\n","        ind_rloss=1\n","        for inputs, labels in train_loader_tqdm:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward pass and optimize\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Print statistics\n","            running_loss += loss.item()\n","            train_loader_tqdm.set_postfix(loss=running_loss / ind_rloss)\n","            ind_rloss +=1\n","\n","        epoch_loss = running_loss / len(trainloader)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","\n","        scheduler.step()\n","        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n","        \n","        # Validation loop (optional)\n","        model.eval()  # Set model to evaluation mode\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for inputs, labels in valloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss /= len(valloader)\n","        val_accuracy = 100 * correct / total\n","        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n","        \n","        # Log validation loss and accuracy\n","        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n","        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n","        \n","        # Early stopping\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model = model\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter > patience:\n","                print(\"Early stopping\")\n","                break\n","                    \n","    # Log the model\n","    mlflow.pytorch.log_model(best_model, model_name)\n","\n","    # End the MLflow run\n","    mlflow.end_run()\n","\n","    print('Finished Training')\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["def Save_mlruns():\n","    print(\"moving to working directory...\")\n","    ! cd /kaggle/working/\n","    print(\"zipping directory...\")\n","    ! zip -r mlruns.zip mlruns\n","    print(\"!!REMEMBER TO DOWNLOAD IT FROM THE OUTPUT SECTION!!\")\n","    print(\"back to home directory...\")\n","    ! cd "]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/30:  20%|█▉        | 2316/11860 [00:43<02:55, 54.33batch/s, loss=5.52]"]}],"source":["# example of training \n","\n","# Define criterion, optimizer and scheduler and other parameters for training\n","opt = \"SGD\"                        # optimizer to be used: [\"Adam\" or \"SGD\"]\n","momentum = 0.9                      # momentum ONLY for SGD optimizer\n","weight_decay = 1e-4                 # weight decay ONLY on Adam optimizer\n","step_size = 5                       # step size for the scheduler\n","gamma = 0.1                         # gamma for the scheduler\n","\n","batch_size = 8                     # batch size\n","num_epochs= 30                        # number of epochs\n","patience = 5                        # patience for early stopping\n","criterion =\"CrossEntropyLoss\"       # loss function to be used: [\"CrossEntropyLoss\", \"MSELoss\", \"L1Loss\", \"NLLLoss\"]\n","lr = 0.01                        # learning rate\n","\n","model_name = \"squeezenet_SGD\"           # model name\n","model = models.SqueezeNet()         # model\n","\n","tr_param = set_training_parameters(model=model,model_name = model_name, opt=opt, lr=lr, weight_decay=weight_decay, \n","                                   momentum=momentum, criterion=criterion, step_size=step_size, gamma=gamma, num_epochs=num_epochs, \n","                                   patience=patience, device=device)\n","\n","#stop eventual mlflow runs\n","mlflow.end_run()\n","train_model(**tr_param, trainloader=trainloader, valloader=valloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if is_kaggle():\n","    Save_mlruns()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5175452,"sourceId":8641640,"sourceType":"datasetVersion"},{"sourceId":182255674,"sourceType":"kernelVersion"},{"sourceId":182257654,"sourceType":"kernelVersion"},{"sourceId":182257811,"sourceType":"kernelVersion"},{"sourceId":182257893,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}
