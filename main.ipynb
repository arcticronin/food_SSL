{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8641640,"sourceType":"datasetVersion","datasetId":5175452},{"sourceId":182255674,"sourceType":"kernelVersion"},{"sourceId":182257245,"sourceType":"kernelVersion"},{"sourceId":182257654,"sourceType":"kernelVersion"},{"sourceId":182257811,"sourceType":"kernelVersion"},{"sourceId":182257893,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport shutil\nimport importlib\nimport sys\n\n# Determine the environment and import preprocessing module accordingly\ndef is_kaggle():\n    return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n\nif is_kaggle():\n    print(\"Running on Kaggle\")\n    # Assuming 'preprocessing.py' and other scripts are in '/kaggle/input'\n    kaggle_input_path = '/kaggle/usr/lib'\n    sys.path.append(kaggle_input_path)\n    \n    import preprocessing_py as preprocessing\n    import models_py as models\n    import utils_py as utils\n   \n    \n    # Install missing libraries on kaggle\n    ! pip install torchsummary\n    ! pip install mlflow\nelse:\n    print(\"Running locally\")\n    import scripts.preprocessing as preprocessing\n    import scripts.models as models\n    import scripts.utils as utils\n    \n    from utils import *\n    \n# Reload the module (if necessary)\nimportlib.reload(preprocessing)\nimportlib.reload(models)\nimportlib.reload(utils)\n\n# Other imports\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nimport torchsummary\nimport torch.optim as optim\n\nimport tqdm\nimport mlflow\nimport mlflow.pytorch","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:22:30.440774Z","iopub.execute_input":"2024-06-08T19:22:30.441168Z","iopub.status.idle":"2024-06-08T19:22:55.848114Z","shell.execute_reply.started":"2024-06-08T19:22:30.441139Z","shell.execute_reply":"2024-06-08T19:22:55.846625Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Running on Kaggle\nRequirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: mlflow in /opt/conda/lib/python3.10/site-packages (2.13.2)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.1)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (5.3.2)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.41)\nRequirement already satisfied: graphene<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.3)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.11.0)\nRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.5.2)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\nRequirement already satisfied: opentelemetry-api<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\nRequirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.3)\nRequirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.2)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.20.3)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (15.0.2)\nRequirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2023.3.post1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.0.1)\nRequirement already satisfied: querystring-parser<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.32.3)\nRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.11.4)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.25)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: gunicorn<23 in /opt/conda/lib/python3.10/site-packages (from mlflow) (22.0.0)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.3)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: aniso8601<10,>=8 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (9.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow) (0.43b0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from querystring-parser<2->mlflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow) (1.14.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#set the correct directory for mlflow tracking\n#mlflow.set_tracking_uri(\"file:./mlruns\")","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:23:01.409892Z","iopub.execute_input":"2024-06-08T19:23:01.410287Z","iopub.status.idle":"2024-06-08T19:23:01.446298Z","shell.execute_reply.started":"2024-06-08T19:23:01.410259Z","shell.execute_reply":"2024-06-08T19:23:01.444908Z"},"trusted":true},"execution_count":44,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43muse_GPU\u001b[49m()\n","\u001b[0;31mNameError\u001b[0m: name 'use_GPU' is not defined"],"ename":"NameError","evalue":"name 'use_GPU' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model = models.SqueezeNet()\nmodel = model.to(device)","metadata":{"ExecuteTime":{"end_time":"2024-06-04T14:24:21.972371Z","start_time":"2024-06-04T14:24:21.961718Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"torchsummary.summary(model, (3, 224, 224));","metadata":{"ExecuteTime":{"end_time":"2024-06-04T14:34:04.612770Z","start_time":"2024-06-04T14:34:04.593346Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"----------------------------------------------------------------\n\n        Layer (type)               Output Shape         Param #\n\n================================================================\n\n            Conv2d-1         [-1, 64, 111, 111]           1,792\n\n              ReLU-2         [-1, 64, 111, 111]               0\n\n         MaxPool2d-3           [-1, 64, 55, 55]               0\n\n            Conv2d-4           [-1, 16, 55, 55]           1,040\n\n              ReLU-5           [-1, 16, 55, 55]               0\n\n            Conv2d-6           [-1, 64, 55, 55]           1,088\n\n              ReLU-7           [-1, 64, 55, 55]               0\n\n            Conv2d-8           [-1, 64, 55, 55]           9,280\n\n              ReLU-9           [-1, 64, 55, 55]               0\n\n             Fire-10          [-1, 128, 55, 55]               0\n\n           Conv2d-11           [-1, 16, 55, 55]           2,064\n\n             ReLU-12           [-1, 16, 55, 55]               0\n\n           Conv2d-13           [-1, 64, 55, 55]           1,088\n\n             ReLU-14           [-1, 64, 55, 55]               0\n\n           Conv2d-15           [-1, 64, 55, 55]           9,280\n\n             ReLU-16           [-1, 64, 55, 55]               0\n\n             Fire-17          [-1, 128, 55, 55]               0\n\n        MaxPool2d-18          [-1, 128, 27, 27]               0\n\n           Conv2d-19           [-1, 32, 27, 27]           4,128\n\n             ReLU-20           [-1, 32, 27, 27]               0\n\n           Conv2d-21          [-1, 128, 27, 27]           4,224\n\n             ReLU-22          [-1, 128, 27, 27]               0\n\n           Conv2d-23          [-1, 128, 27, 27]          36,992\n\n             ReLU-24          [-1, 128, 27, 27]               0\n\n             Fire-25          [-1, 256, 27, 27]               0\n\n           Conv2d-26           [-1, 32, 27, 27]           8,224\n\n             ReLU-27           [-1, 32, 27, 27]               0\n\n           Conv2d-28          [-1, 128, 27, 27]           4,224\n\n             ReLU-29          [-1, 128, 27, 27]               0\n\n           Conv2d-30          [-1, 128, 27, 27]          36,992\n\n             ReLU-31          [-1, 128, 27, 27]               0\n\n             Fire-32          [-1, 256, 27, 27]               0\n\n        MaxPool2d-33          [-1, 256, 13, 13]               0\n\n           Conv2d-34           [-1, 48, 13, 13]          12,336\n\n             ReLU-35           [-1, 48, 13, 13]               0\n\n           Conv2d-36          [-1, 192, 13, 13]           9,408\n\n             ReLU-37          [-1, 192, 13, 13]               0\n\n           Conv2d-38          [-1, 192, 13, 13]          83,136\n\n             ReLU-39          [-1, 192, 13, 13]               0\n\n             Fire-40          [-1, 384, 13, 13]               0\n\n           Conv2d-41           [-1, 48, 13, 13]          18,480\n\n             ReLU-42           [-1, 48, 13, 13]               0\n\n           Conv2d-43          [-1, 192, 13, 13]           9,408\n\n             ReLU-44          [-1, 192, 13, 13]               0\n\n           Conv2d-45          [-1, 192, 13, 13]          83,136\n\n             ReLU-46          [-1, 192, 13, 13]               0\n\n             Fire-47          [-1, 384, 13, 13]               0\n\n           Conv2d-48           [-1, 64, 13, 13]          24,640\n\n             ReLU-49           [-1, 64, 13, 13]               0\n\n           Conv2d-50          [-1, 256, 13, 13]          16,640\n\n             ReLU-51          [-1, 256, 13, 13]               0\n\n           Conv2d-52          [-1, 256, 13, 13]         147,712\n\n             ReLU-53          [-1, 256, 13, 13]               0\n\n             Fire-54          [-1, 512, 13, 13]               0\n\n           Conv2d-55           [-1, 64, 13, 13]          32,832\n\n             ReLU-56           [-1, 64, 13, 13]               0\n\n           Conv2d-57          [-1, 256, 13, 13]          16,640\n\n             ReLU-58          [-1, 256, 13, 13]               0\n\n           Conv2d-59          [-1, 256, 13, 13]         147,712\n\n             ReLU-60          [-1, 256, 13, 13]               0\n\n             Fire-61          [-1, 512, 13, 13]               0\n\n          Dropout-62          [-1, 512, 13, 13]               0\n\n           Conv2d-63          [-1, 251, 13, 13]         128,763\n\n             ReLU-64          [-1, 251, 13, 13]               0\n\nAdaptiveAvgPool2d-65            [-1, 251, 1, 1]               0\n\n================================================================\n\nTotal params: 851,259\n\nTrainable params: 851,259\n\nNon-trainable params: 0\n\n----------------------------------------------------------------\n\nInput size (MB): 0.57\n\nForward/backward pass size (MB): 51.83\n\nParams size (MB): 3.25\n\nEstimated Total Size (MB): 55.65\n\n----------------------------------------------------------------\n"}]},{"cell_type":"code","source":"# Load data\nfolder_structure = preprocessing.create_dataset()\n# transform it in a dataframe and list the number of images per class in the folders\na = pd.DataFrame([(k, len(v)) for k,v in folder_structure[0].items()], \n                    columns=['class', 'count'])\nb = pd.DataFrame([(k, len(v)) for k,v in folder_structure[1].items()], \n                    columns=['class', 'count'])\nimage_counts = pd.merge(a, \n                        b, \n                        on='class', \n                        how='outer', \n                        suffixes=('_train', '_test'))","metadata":{"ExecuteTime":{"end_time":"2024-06-03T16:31:14.275625Z","start_time":"2024-06-03T16:30:54.879615Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"Populating data/train\n\nPopulating data/test\n"}]},{"cell_type":"code","source":"image_counts.head()","metadata":{"ExecuteTime":{"end_time":"2024-06-03T16:31:32.731631Z","start_time":"2024-06-03T16:31:32.724127Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>count_train</th>\n","      <th>count_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>adobo</td>\n","      <td>498</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ambrosia_food</td>\n","      <td>569</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>apple_pie</td>\n","      <td>549</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>apple_turnover</td>\n","      <td>504</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>applesauce</td>\n","      <td>484</td>\n","      <td>39</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            class  count_train  count_test\n","0           adobo          498          43\n","1   ambrosia_food          569          35\n","2       apple_pie          549          41\n","3  apple_turnover          504          43\n","4      applesauce          484          39"]},"metadata":{}}]},{"cell_type":"code","source":"image_counts.loc[np.argmin(image_counts['count_train']),:]","metadata":{"ExecuteTime":{"end_time":"2024-06-03T16:31:34.075806Z","start_time":"2024-06-03T16:31:34.072217Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":["class          marble_cake\n","count_train             34\n","count_test              49\n","Name: 143, dtype: object"]},"metadata":{}}]},{"cell_type":"code","source":"preprocessing.create_validation(42);","metadata":{"ExecuteTime":{"end_time":"2024-06-03T16:33:42.664214Z","start_time":"2024-06-03T16:33:42.030197Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    # resize \n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(224),\n    transforms.ToTensor(),\n    # Normalize pixel values\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load the training dataset\ntrainset = torchvision.datasets.ImageFolder(root='data/train', transform=transform)\n\n# Create data loader for training data with batch size 4 and shuffling\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n\nvalset = torchvision.datasets.ImageFolder(root='data/val', transform=transform)\n\nvalloader = torch.utils.data.DataLoader(valset, batch_size=16, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.ImageFolder(root='data/test', transform=transform)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)","metadata":{"ExecuteTime":{"end_time":"2024-06-03T17:08:44.782398Z","start_time":"2024-06-03T17:08:44.644528Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define criterion, optimizer and scheduler and other parameters for training\nopt = \"Adam\"                        # optimizer to be used: [\"Adam\" or \"SGD\"]\nmomentum = 0.9                      # momentum ONLY for SGD optimizer\nweight_decay = 1e-4                 # weight decay ONLY on Adam optimizer\nstep_size = 7                       # step size for the scheduler\ngamma = 0.1                         # gamma for the scheduler\n\nbatch_size = 8                      # batch size\nnum_epochs=10                       # number of epochs\npatience = 3                        # patience for early stopping\ncriterion =\"CrossEntropyLoss\"       # loss function to be used: [\"CrossEntropyLoss\", \"MSELoss\", \"L1Loss\", \"NLLLoss\"]\nlr = 5e-5                           # learning rate\n\nmodel_name = \"squeezenet\"           # model name\nmodel = models.SqueezeNet()         # model\n\n\n\n#set the optimizer\nif opt == \"Adam\":\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\nelif opt == \"SGD\":\n    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\nelse:\n    print(\"Invalid optimizer\")\n\n#set the criterion\nif criterion == \"CrossEntropyLoss\":\n    criterion = nn.CrossEntropyLoss()\nelif criterion == \"MSELoss\":\n    criterion = nn.MSELoss()\nelif criterion == \"L1Loss\":\n    criterion = nn.L1Loss()\nelif criterion == \"NLLLoss\":\n    criterion = nn.NLLLoss()\nelse:\n    print(\"Invalid criterion\")\n\n#set the scheduler\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\n# Upload model to correct device\nmodel = model.to(device)","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def set_training_parameters(model, model_name, opt, lr, weight_decay, momentum, criterion, step_size, gamma, num_epochs, patience, device):\n\n    #set the optimizer\n    if opt == \"Adam\":\n        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n    elif opt == \"SGD\":\n        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n    else:\n        print(\"Invalid optimizer\")\n\n    #set the criterion\n    if criterion == \"CrossEntropyLoss\":\n        criterion = nn.CrossEntropyLoss()\n    elif criterion == \"MSELoss\":\n        criterion = nn.MSELoss()\n    elif criterion == \"L1Loss\":\n        criterion = nn.L1Loss()\n    elif criterion == \"NLLLoss\":\n        criterion = nn.NLLLoss()\n    else:\n        print(\"Invalid criterion\")\n\n    #set the scheduler\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\n    # Upload model to correct device\n    model = model.to(device)\n    \n    training_parameters = {}\n    training_parameters['model'] = model\n    training_parameters['model_name'] = model_name\n    training_parameters['criterion'] = criterion\n    training_parameters['optimizer'] = optimizer\n    training_parameters['scheduler'] = scheduler\n    training_parameters['num_epochs'] = num_epochs\n    training_parameters['patience'] = patience\n    \n    return training_parameters","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Training function based on above parameters\ndef train_model(model, model_name, trainloader, valloader, criterion, optimizer, scheduler, num_epochs=10, patience=3 ):\n\n    mlflow.start_run(run_name=model_name)\n\n    # Log model parameters\n    mlflow.log_param(\"optimizer\", opt)\n    mlflow.log_param(\"learning_rate\", lr)\n    mlflow.log_param(\"batch_size\", batch_size)\n    mlflow.log_param(\"num_epochs\", num_epochs)\n    mlflow.log_param(\"momentum\", momentum)\n    mlflow.log_param(\"weight_decay\", weight_decay)\n    mlflow.log_param(\"step_size\", step_size)\n    mlflow.log_param(\"gamma\", gamma)\n    mlflow.log_param(\"patience\", patience)\n\n\n    patience_counter = 0\n    best_model = None\n    best_loss = np.inf\n\n    for epoch in range(num_epochs):\n        model.train()  # Set model to training mode\n        running_loss = 0.0\n        train_loader_tqdm = tqdm.tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", \n                                unit=\"batch\")\n        \n        for inputs, labels in train_loader_tqdm:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n\n            # Print statistics\n            running_loss += loss.item()\n            train_loader_tqdm.set_postfix(loss=running_loss / len(trainloader))\n\n        epoch_loss = running_loss / len(trainloader)\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n\n        scheduler.step()\n        mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n        \n        # Validation loop (optional)\n        model.eval()  # Set model to evaluation mode\n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for inputs, labels in valloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_loss /= len(valloader)\n        val_accuracy = 100 * correct / total\n        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n        \n        # Log validation loss and accuracy\n        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n        \n        # Early stopping\n        if val_loss < best_loss:\n            best_loss = val_loss\n            best_model = model\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter > patience:\n                print(\"Early stopping\")\n                break\n                    \n    # Log the model\n    mlflow.pytorch.log_model(best_model, model_name)\n\n    # End the MLflow run\n    mlflow.end_run()\n\n    print('Finished Training')\n","metadata":{"ExecuteTime":{"end_time":"2024-06-03T17:23:52.036996Z","start_time":"2024-06-03T17:20:54.527188Z"},"collapsed":false,"jupyter":{"outputs_hidden":false}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# example of training \n\n# Define criterion, optimizer and scheduler and other parameters for training\nopt = \"Adam\"                        # optimizer to be used: [\"Adam\" or \"SGD\"]\nmomentum = 0.9                      # momentum ONLY for SGD optimizer\nweight_decay = 1e-4                 # weight decay ONLY on Adam optimizer\nstep_size = 7                       # step size for the scheduler\ngamma = 1                         # gamma for the scheduler\n\nbatch_size = 32                     # batch size\nnum_epochs= 30                        # number of epochs\npatience = 3                        # patience for early stopping\ncriterion =\"CrossEntropyLoss\"       # loss function to be used: [\"CrossEntropyLoss\", \"MSELoss\", \"L1Loss\", \"NLLLoss\"]\nlr = 0.001                        # learning rate\n\nmodel_name = \"squeezenet\"           # model name\nmodel = models.SqueezeNet()         # model\n\ntr_param = set_training_parameters(model=model,model_name = model_name, opt=opt, lr=lr, weight_decay=weight_decay, \n                                   momentum=momentum, criterion=criterion, step_size=step_size, gamma=gamma, num_epochs=num_epochs, \n                                   patience=patience, device=device)\n\n#stop eventual mlflow runs\nmlflow.end_run()\ntrain_model(**tr_param, trainloader=trainloader, valloader=valloader)","metadata":{},"execution_count":20,"outputs":[{"name":"stderr","output_type":"stream","text":"Epoch 1/30:  12%|█▏        | 1473/11860 [12:01<1:24:49,  2.04batch/s, loss=0.686]\n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#stop eventual mlflow runs\u001b[39;00m\n\u001b[1;32m     24\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mend_run()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtr_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalloader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[19], line 39\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, trainloader, valloader, criterion, optimizer, scheduler, num_epochs, patience)\u001b[0m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":"model_from_scratch = models.SqueezeNet()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nmlflow.end_run()\ntrain_model(model_from_scratch,\n            \"netFromScratch\", \n            trainloader, \n            valloader, \n            criterion, \n            optimizer, \n            scheduler,\n            num_epochs=10, \n            device=device)","metadata":{},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"Epoch 1/10: 100%|██████████| 14810/14810 [21:25<00:00, 11.52batch/s, loss=5.6] "},{"name":"stdout","output_type":"stream","text":"Epoch [1/10], Loss: 5.6000\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Validation Loss: 5.6158, Validation Accuracy: 0.41%\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/10: 100%|██████████| 14810/14810 [21:59<00:00, 11.23batch/s, loss=5.6] "},{"name":"stdout","output_type":"stream","text":"Epoch [2/10], Loss: 5.6001\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Validation Loss: 5.6157, Validation Accuracy: 0.40%\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/10:  39%|███▉      | 5845/14810 [09:11<14:05, 10.60batch/s, loss=2.21]   \n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_from_scratch \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSqueezeNet()\n\u001b[1;32m      6\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mend_run()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_from_scratch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnetFromScratch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, trainloader, valloader, criterion, optimizer, scheduler, num_epochs, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n#mlflow.end_run()\nmodel = models.SqueezeNet()\nmodel.load_state_dict(torch.load('netFromSSL.pth'))\ntrain_model(model,\n            \"netFromSSL\",\n            trainloader,\n            valloader,\n            criterion,\n            optimizer,\n            scheduler,\n            num_epochs=4,\n            device=device)","metadata":{},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"Epoch 1/4: 100%|██████████| 14810/14810 [22:05<00:00, 11.18batch/s, loss=5.55]  "},{"name":"stdout","output_type":"stream","text":"Epoch [1/4], Loss: 5.5479\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Validation Loss: 5.5522, Validation Accuracy: 0.39%\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/4: 100%|██████████| 14810/14810 [21:32<00:00, 11.46batch/s, loss=5.55]"},{"name":"stdout","output_type":"stream","text":"Epoch [2/4], Loss: 5.5481\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Validation Loss: 5.5522, Validation Accuracy: 0.39%\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/4: 100%|██████████| 14810/14810 [21:28<00:00, 11.50batch/s, loss=5.55]"},{"name":"stdout","output_type":"stream","text":"Epoch [3/4], Loss: 5.5479\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Validation Loss: 5.5522, Validation Accuracy: 0.39%\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/4: 100%|██████████| 14810/14810 [21:28<00:00, 11.49batch/s, loss=5.55]"},{"name":"stdout","output_type":"stream","text":"Epoch [4/4], Loss: 5.5478\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Validation Loss: 5.5522, Validation Accuracy: 0.39%\n\nFinished Training\n"}]},{"cell_type":"code","source":"mlflow.end_run()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best hyperparameters from github non provato\n\n# transformations\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ]),\n}\n\ndata_dir = 'path_to_foodx251_dataset'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialize the model\nmodel = models.squeezenet1_1(pretrained=True)\nmodel.classifier[1] = nn.Conv2d(512, len(class_names), kernel_size=(1,1), stride=(1,1))\nmodel.num_classes = len(class_names)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n# Training function\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n\n        for inputs, labels in dataloaders['train']:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        \n        epoch_loss = running_loss / dataset_sizes['train']\n        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n        scheduler.step()\n\n        # Validation loop\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for inputs, labels in dataloaders['val']:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        val_loss /= dataset_sizes['val']\n        val_accuracy = correct / total\n        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n\n    return model\n\n# Train the model\nmodel = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)","metadata":{},"execution_count":null,"outputs":[]}]}