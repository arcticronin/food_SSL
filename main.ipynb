{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.429316Z",
     "start_time": "2024-06-04T14:24:21.426058Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import importlib\n",
    "import scripts.preprocessing as preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "import scripts.models as models\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abfb3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "device = use_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aec841b882f4ea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.972371Z",
     "start_time": "2024-06-04T14:24:21.961718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.SqueezeNet()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd403b9a5a3434e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:34:04.612770Z",
     "start_time": "2024-06-04T14:34:04.593346Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 127, 127]           1,792\n",
      "              ReLU-2         [-1, 64, 127, 127]               0\n",
      "         MaxPool2d-3           [-1, 64, 63, 63]               0\n",
      "            Conv2d-4           [-1, 16, 63, 63]           1,040\n",
      "              ReLU-5           [-1, 16, 63, 63]               0\n",
      "            Conv2d-6           [-1, 64, 63, 63]           1,088\n",
      "              ReLU-7           [-1, 64, 63, 63]               0\n",
      "            Conv2d-8           [-1, 64, 63, 63]           9,280\n",
      "              ReLU-9           [-1, 64, 63, 63]               0\n",
      "             Fire-10          [-1, 128, 63, 63]               0\n",
      "           Conv2d-11           [-1, 16, 63, 63]           2,064\n",
      "             ReLU-12           [-1, 16, 63, 63]               0\n",
      "           Conv2d-13           [-1, 64, 63, 63]           1,088\n",
      "             ReLU-14           [-1, 64, 63, 63]               0\n",
      "           Conv2d-15           [-1, 64, 63, 63]           9,280\n",
      "             ReLU-16           [-1, 64, 63, 63]               0\n",
      "             Fire-17          [-1, 128, 63, 63]               0\n",
      "        MaxPool2d-18          [-1, 128, 31, 31]               0\n",
      "           Conv2d-19           [-1, 32, 31, 31]           4,128\n",
      "             ReLU-20           [-1, 32, 31, 31]               0\n",
      "           Conv2d-21          [-1, 128, 31, 31]           4,224\n",
      "             ReLU-22          [-1, 128, 31, 31]               0\n",
      "           Conv2d-23          [-1, 128, 31, 31]          36,992\n",
      "             ReLU-24          [-1, 128, 31, 31]               0\n",
      "             Fire-25          [-1, 256, 31, 31]               0\n",
      "           Conv2d-26           [-1, 32, 31, 31]           8,224\n",
      "             ReLU-27           [-1, 32, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]           4,224\n",
      "             ReLU-29          [-1, 128, 31, 31]               0\n",
      "           Conv2d-30          [-1, 128, 31, 31]          36,992\n",
      "             ReLU-31          [-1, 128, 31, 31]               0\n",
      "             Fire-32          [-1, 256, 31, 31]               0\n",
      "        MaxPool2d-33          [-1, 256, 15, 15]               0\n",
      "           Conv2d-34           [-1, 48, 15, 15]          12,336\n",
      "             ReLU-35           [-1, 48, 15, 15]               0\n",
      "           Conv2d-36          [-1, 192, 15, 15]           9,408\n",
      "             ReLU-37          [-1, 192, 15, 15]               0\n",
      "           Conv2d-38          [-1, 192, 15, 15]          83,136\n",
      "             ReLU-39          [-1, 192, 15, 15]               0\n",
      "             Fire-40          [-1, 384, 15, 15]               0\n",
      "           Conv2d-41           [-1, 48, 15, 15]          18,480\n",
      "             ReLU-42           [-1, 48, 15, 15]               0\n",
      "           Conv2d-43          [-1, 192, 15, 15]           9,408\n",
      "             ReLU-44          [-1, 192, 15, 15]               0\n",
      "           Conv2d-45          [-1, 192, 15, 15]          83,136\n",
      "             ReLU-46          [-1, 192, 15, 15]               0\n",
      "             Fire-47          [-1, 384, 15, 15]               0\n",
      "           Conv2d-48           [-1, 64, 15, 15]          24,640\n",
      "             ReLU-49           [-1, 64, 15, 15]               0\n",
      "           Conv2d-50          [-1, 256, 15, 15]          16,640\n",
      "             ReLU-51          [-1, 256, 15, 15]               0\n",
      "           Conv2d-52          [-1, 256, 15, 15]         147,712\n",
      "             ReLU-53          [-1, 256, 15, 15]               0\n",
      "             Fire-54          [-1, 512, 15, 15]               0\n",
      "           Conv2d-55           [-1, 64, 15, 15]          32,832\n",
      "             ReLU-56           [-1, 64, 15, 15]               0\n",
      "           Conv2d-57          [-1, 256, 15, 15]          16,640\n",
      "             ReLU-58          [-1, 256, 15, 15]               0\n",
      "           Conv2d-59          [-1, 256, 15, 15]         147,712\n",
      "             ReLU-60          [-1, 256, 15, 15]               0\n",
      "             Fire-61          [-1, 512, 15, 15]               0\n",
      "          Dropout-62          [-1, 512, 15, 15]               0\n",
      "           Conv2d-63          [-1, 251, 15, 15]         128,763\n",
      "             ReLU-64          [-1, 251, 15, 15]               0\n",
      "AdaptiveAvgPool2d-65            [-1, 251, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 851,259\n",
      "Trainable params: 851,259\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 68.20\n",
      "Params size (MB): 3.25\n",
      "Estimated Total Size (MB): 72.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 256, 256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14ecb8153d3b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:14.275625Z",
     "start_time": "2024-06-03T16:30:54.879615Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating data/train\n",
      "Populating data/test\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "folder_structure = preprocessing.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64bae5e0016840c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:32.022652Z",
     "start_time": "2024-06-03T16:31:32.017921Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform it in a dataframe\n",
    "a = pd.DataFrame([(k, len(v)) for k,v in folder_structure[0].items()], columns=['class', 'count'])\n",
    "b = pd.DataFrame([(k, len(v)) for k,v in folder_structure[1].items()], columns=['class', 'count'])\n",
    "image_counts = pd.merge(a, b, on='class', how='outer', suffixes=('_train', '_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc827c60ede55707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:32.731631Z",
     "start_time": "2024-06-03T16:31:32.724127Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count_train</th>\n",
       "      <th>count_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adobo</td>\n",
       "      <td>498</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambrosia_food</td>\n",
       "      <td>569</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple_pie</td>\n",
       "      <td>549</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple_turnover</td>\n",
       "      <td>504</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applesauce</td>\n",
       "      <td>484</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>vol_au_vent</td>\n",
       "      <td>447</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>waffle</td>\n",
       "      <td>376</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>welsh_rarebit</td>\n",
       "      <td>319</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>wonton</td>\n",
       "      <td>513</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>ziti</td>\n",
       "      <td>392</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              class  count_train  count_test\n",
       "0             adobo          498          43\n",
       "1     ambrosia_food          569          35\n",
       "2         apple_pie          549          41\n",
       "3    apple_turnover          504          43\n",
       "4        applesauce          484          39\n",
       "..              ...          ...         ...\n",
       "246     vol_au_vent          447          57\n",
       "247          waffle          376          44\n",
       "248   welsh_rarebit          319          41\n",
       "249          wonton          513          48\n",
       "250            ziti          392          51\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f834241754535d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:31:34.075806Z",
     "start_time": "2024-06-03T16:31:34.072217Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class          marble_cake\n",
       "count_train             34\n",
       "count_test              49\n",
       "Name: 143, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_counts.loc[np.argmin(image_counts['count_train']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb3e757ecebab77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:33:42.664214Z",
     "start_time": "2024-06-03T16:33:42.030197Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessing.create_validation(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1979fcf16872184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:08:44.782398Z",
     "start_time": "2024-06-03T17:08:44.644528Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # Convert PIL images to PyTorch tensors\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize pixel values\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # Resize images to a common size\n",
    "    transforms.Resize(size=(64,64)) #forse da ridurre? abbiamo troppe immagini\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "trainset = torchvision.datasets.ImageFolder(root='data/train', transform=transform)\n",
    "\n",
    "# Create data loader for training data with batch size 4 and shuffling\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root='data/val', transform=transform)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='data/test', transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "687ee36802463d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:02:39.667807Z",
     "start_time": "2024-06-03T17:02:39.662949Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EfficientCNN(nn.Module):\n",
    "    def __init__(self, num_classes=251):\n",
    "        super(EfficientCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Batch Normalization layers\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 4 , 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU and MaxPooling\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 4)\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6875b446f2893898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:02:39.995708Z",
     "start_time": "2024-06-03T17:02:39.989249Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=251, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientCNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d72c7580c4695331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:02:40.398829Z",
     "start_time": "2024-06-03T17:02:40.390273Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             896\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "            Conv2d-3           [-1, 64, 32, 32]          18,496\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "       BatchNorm2d-8            [-1, 256, 8, 8]             512\n",
      "            Linear-9                  [-1, 512]         524,800\n",
      "           Linear-10                  [-1, 251]         128,763\n",
      "================================================================\n",
      "Total params: 1,042,939\n",
      "Trainable params: 1,042,939\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 3.76\n",
      "Params size (MB): 3.98\n",
      "Estimated Total Size (MB): 7.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "torchsummary.summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab488f0446a04bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:06:11.210169Z",
     "start_time": "2024-06-03T17:06:11.207247Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## train the model\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "patience = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b34a42cc8cb5f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T17:23:52.036996Z",
     "start_time": "2024-06-03T17:20:54.527188Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 5.349\n",
      "[1,  4000] loss: 5.341\n",
      "[1,  6000] loss: 5.328\n",
      "[1,  8000] loss: 5.333\n",
      "[1, 10000] loss: 5.323\n",
      "[2,  2000] loss: 5.293\n",
      "[2,  4000] loss: 5.293\n",
      "[2,  6000] loss: 5.288\n",
      "[2,  8000] loss: 5.265\n"
     ]
    }
   ],
   "source": [
    "train_loss=[] # store the training loss\n",
    "\n",
    "best_val_loss = np.inf # initialize the best validation loss to infinity for patience\n",
    "patience_counter = 0 # initialize the counter for patience\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        # Add the loss to the training set's running loss\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        # we  keep the variable separated because we want to print the running loss \n",
    "        #every 2000 mini-batches and len(trainloader)%2000 is not 0\n",
    "\n",
    "        # Print the loss every 2000 mini-batches\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    # Add the epoch loss to the training loss list\n",
    "    train_loss.append(epoch_loss/len(trainloader))\n",
    "    if(epoch_loss/len(trainloader) < best_val_loss):\n",
    "        best_val_loss = epoch_loss/len(trainloader)\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter > patience:\n",
    "            print(\"Early stopping at epoch \", epoch)\n",
    "            break\n",
    "        \n",
    "    # Step the scheduler  \n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
