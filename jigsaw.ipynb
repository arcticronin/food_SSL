{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f42a78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.429316Z",
     "start_time": "2024-06-04T14:24:21.426058Z"
    },
    "_cell_guid": "f116968c-2b35-4c3d-af3f-fa2101ddfe06",
    "_uuid": "3911171b-3158-4629-8d20-1c1d57f25d85",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-14T12:31:54.835578Z",
     "iopub.status.busy": "2024-06-14T12:31:54.835304Z",
     "iopub.status.idle": "2024-06-14T12:32:23.051773Z",
     "shell.execute_reply": "2024-06-14T12:32:23.050936Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 28.223869,
     "end_time": "2024-06-14T12:32:23.054122",
     "exception": false,
     "start_time": "2024-06-14T12:31:54.830253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Kaggle\n",
      "Collecting mlflow\r\n",
      "  Downloading mlflow-2.13.2-py3-none-any.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\r\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.1)\r\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow)\r\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\r\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.0.0)\r\n",
      "Requirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4)\r\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.41)\r\n",
      "Collecting graphene<4 (from mlflow)\r\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\r\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.11.0)\r\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.5.2)\r\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\r\n",
      "Requirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\r\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.22.0)\r\n",
      "Requirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow) (21.3)\r\n",
      "Requirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.1)\r\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.20.3)\r\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (14.0.2)\r\n",
      "Requirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2023.3.post1)\r\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow) (6.0.1)\r\n",
      "Collecting querystring-parser<2 (from mlflow)\r\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\r\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.32.3)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\r\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.11.4)\r\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.25)\r\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (0.4.4)\r\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.2)\r\n",
      "Collecting gunicorn<23 (from mlflow)\r\n",
      "  Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\r\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.3)\r\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\r\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\r\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\r\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow) (1.2.14)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow) (0.43b0)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2023.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from querystring-parser<2->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.2.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow) (1.14.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\r\n",
      "Downloading mlflow-2.13.2-py3-none-any.whl (25.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\r\n",
      "Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\r\n",
      "Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\r\n",
      "Installing collected packages: aniso8601, querystring-parser, graphql-core, cachetools, gunicorn, graphql-relay, graphene, mlflow\r\n",
      "  Attempting uninstall: cachetools\r\n",
      "    Found existing installation: cachetools 4.2.4\r\n",
      "    Uninstalling cachetools-4.2.4:\r\n",
      "      Successfully uninstalled cachetools-4.2.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.4.1 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.4.1 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aniso8601-9.0.1 cachetools-5.3.2 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 mlflow-2.13.2 querystring-parser-1.2.4\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Determine the environment and import preprocessing module accordingly\n",
    "def is_kaggle():\n",
    "    return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "if is_kaggle():\n",
    "    print(\"Running on Kaggle\")\n",
    "    # Assuming 'preprocessing.py' and other scripts are in '/kaggle/input'\n",
    "    kaggle_input_path = '/kaggle/usr/lib'\n",
    "    sys.path.append(kaggle_input_path)\n",
    "    \n",
    "    import utils_py.utils_py as utils\n",
    "   \n",
    "    \n",
    "    # Install missing libraries on kaggle\n",
    "    ! pip install mlflow\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    import scripts.utils as utils\n",
    "    \n",
    "    \n",
    "importlib.reload(utils)\n",
    "\n",
    "# Other imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import random\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ed94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:24:21.972371Z",
     "start_time": "2024-06-04T14:24:21.961718Z"
    },
    "_cell_guid": "89b153f8-aec3-448e-980e-7f5a4a75bdab",
    "_uuid": "bcf02603-0da4-4e1a-b3af-dc0777cf55c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-14T12:32:23.069669Z",
     "iopub.status.busy": "2024-06-14T12:32:23.068661Z",
     "iopub.status.idle": "2024-06-14T12:32:23.516175Z",
     "shell.execute_reply": "2024-06-14T12:32:23.515391Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.457298,
     "end_time": "2024-06-14T12:32:23.518531",
     "exception": false,
     "start_time": "2024-06-14T12:32:23.061233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = models.StormModel(num_classes=9, dropout=0.1)\n",
    "#model.load_state_dict(torch.load(\"/kaggle/input/colorization_edition/pytorch/18epochs/1/SSL_n17_ep.pth\"))\n",
    "model.to(device)\n",
    "#torchsummary.summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdf5583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T12:32:23.553447Z",
     "iopub.status.busy": "2024-06-14T12:32:23.553149Z",
     "iopub.status.idle": "2024-06-14T12:32:23.570241Z",
     "shell.execute_reply": "2024-06-14T12:32:23.569469Z"
    },
    "papermill": {
     "duration": 0.026279,
     "end_time": "2024-06-14T12:32:23.572040",
     "exception": false,
     "start_time": "2024-06-14T12:32:23.545761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JigsawPuzzleDataset(Dataset):\n",
    "    def __init__(self, image_files, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Divide the image into 9 pieces\n",
    "        pieces = self.divide_image(image)\n",
    "        \n",
    "        # swap two random pieces and get the label\n",
    "        pieces, label = self.swap_pieces(pieces)\n",
    "        \n",
    "        # concatenate pieces back together\n",
    "        jigsaw_image = self.concat_pieces(pieces)\n",
    "        \n",
    "        if self.transform:\n",
    "            jigsaw_image = self.transform(jigsaw_image)\n",
    "        \n",
    "        return jigsaw_image, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    def divide_image(self, image):\n",
    "        w, h = image.size\n",
    "        piece_w, piece_h = w // 3, h // 3\n",
    "        pieces = []\n",
    "\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                left = j * piece_w\n",
    "                top = i * piece_h\n",
    "                right = left + piece_w\n",
    "                bottom = top + piece_h\n",
    "                pieces.append(image.crop((left, top, right, bottom)))\n",
    "\n",
    "        return pieces\n",
    "\n",
    "    def swap_pieces(self, pieces):\n",
    "        idx1, idx2 = random.sample(range(9), 2)\n",
    "        pieces[idx1], pieces[idx2] = pieces[idx2], pieces[idx1]\n",
    "        \n",
    "        # Binary map indicating swapped pieces\n",
    "        label = [0] * 9\n",
    "        label[idx1] = 1\n",
    "        label[idx2] = 1\n",
    "        \n",
    "        return pieces, label\n",
    "\n",
    "    def concat_pieces(self, pieces):\n",
    "        piece_w, piece_h = pieces[0].size\n",
    "        jigsaw_image = Image.new('RGB', (piece_w * 3, piece_h * 3))\n",
    "\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                piece = pieces[i * 3 + j]\n",
    "                jigsaw_image.paste(piece, (j * piece_w, i * piece_h))\n",
    "\n",
    "        return jigsaw_image\n",
    "\n",
    "# Utility function to split the dataset\n",
    "def create_train_test_loaders(image_folder, transform, test_size=0.2, batch_size=4, random_state=42):\n",
    "    # List all image files\n",
    "    \n",
    "    ## version to work on the second dataset\n",
    "    \n",
    "    # image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('jpg', 'png'))]\n",
    "    \n",
    "    \n",
    "    ## version to work on the main dataset\n",
    "    \n",
    "    image_files = []\n",
    "    for root, _, files in os.walk(image_folder):\n",
    "        for file in files:\n",
    "            if os.path.isfile(os.path.join(root, file)):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    \n",
    "    ## end of the special version\n",
    "    \n",
    "    # Split the image files into train and test sets\n",
    "    train_files, test_files = train_test_split(image_files, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = JigsawPuzzleDataset(train_files, transform=transform)\n",
    "    test_dataset = JigsawPuzzleDataset(test_files, transform=transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers = 4)\n",
    "    \n",
    "    return train_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8680cf6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T12:32:23.586957Z",
     "iopub.status.busy": "2024-06-14T12:32:23.586661Z",
     "iopub.status.idle": "2024-06-14T12:33:00.556829Z",
     "shell.execute_reply": "2024-06-14T12:33:00.556011Z"
    },
    "papermill": {
     "duration": 36.980554,
     "end_time": "2024-06-14T12:33:00.559185",
     "exception": false,
     "start_time": "2024-06-14T12:32:23.578631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # no normalization for the plot\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#image_folder = '/kaggle/input/foodsslimages/images'\n",
    "image_folder = '/kaggle/input/food-dataset-sl/data/train'\n",
    "train_dataloader, test_dataloader = create_train_test_loaders(image_folder, transform, test_size=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb274a59",
   "metadata": {
    "_cell_guid": "da96459e-3716-4088-bcfc-f729c81333e7",
    "_uuid": "41cfe0f8-9676-4c2d-9e72-7922d24af5b1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-14T12:33:00.574862Z",
     "iopub.status.busy": "2024-06-14T12:33:00.574110Z",
     "iopub.status.idle": "2024-06-14T12:33:00.579774Z",
     "shell.execute_reply": "2024-06-14T12:33:00.579015Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015331,
     "end_time": "2024-06-14T12:33:00.581632",
     "exception": false,
     "start_time": "2024-06-14T12:33:00.566301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5da324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T12:33:00.596308Z",
     "iopub.status.busy": "2024-06-14T12:33:00.596033Z",
     "iopub.status.idle": "2024-06-14T13:28:14.668841Z",
     "shell.execute_reply": "2024-06-14T13:28:14.667695Z"
    },
    "papermill": {
     "duration": 3314.082416,
     "end_time": "2024-06-14T13:28:14.670809",
     "exception": false,
     "start_time": "2024-06-14T12:33:00.588393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 2372/2372 [03:29<00:00, 11.33batch/s, loss=0.0252]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0392, Exact Match Ratio: 0.91758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 2372/2372 [02:07<00:00, 18.56batch/s, loss=0.027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0263, Exact Match Ratio: 0.94266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 2372/2372 [02:10<00:00, 18.17batch/s, loss=0.0191]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0217, Exact Match Ratio: 0.95700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 2372/2372 [02:09<00:00, 18.35batch/s, loss=0.0293]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0149, Exact Match Ratio: 0.96796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 2372/2372 [02:08<00:00, 18.39batch/s, loss=0.0104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0083, Exact Match Ratio: 0.98145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 2372/2372 [02:09<00:00, 18.30batch/s, loss=0.00221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0066, Exact Match Ratio: 0.98535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 2372/2372 [02:09<00:00, 18.30batch/s, loss=3.77e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0062, Exact Match Ratio: 0.98630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 2372/2372 [02:11<00:00, 18.08batch/s, loss=6.21e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0047, Exact Match Ratio: 0.98946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 2372/2372 [02:11<00:00, 18.08batch/s, loss=0.00089]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0046, Exact Match Ratio: 0.99030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 2372/2372 [02:10<00:00, 18.12batch/s, loss=0.000172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0044, Exact Match Ratio: 0.99051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 2372/2372 [02:10<00:00, 18.12batch/s, loss=3.04e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0035, Exact Match Ratio: 0.99236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 2372/2372 [02:13<00:00, 17.74batch/s, loss=3.37e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0029, Exact Match Ratio: 0.99352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 2372/2372 [02:11<00:00, 18.02batch/s, loss=3.15e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0033, Exact Match Ratio: 0.99310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 2372/2372 [02:12<00:00, 17.88batch/s, loss=0.00221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0031, Exact Match Ratio: 0.99352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 2372/2372 [02:13<00:00, 17.83batch/s, loss=0.0124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0031, Exact Match Ratio: 0.99352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 2372/2372 [02:12<00:00, 17.87batch/s, loss=1.85e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025, Exact Match Ratio: 0.99426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 2372/2372 [02:12<00:00, 17.94batch/s, loss=1.78e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Exact Match Ratio: 0.99410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 2372/2372 [02:19<00:00, 17.00batch/s, loss=0.000123]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0025, Exact Match Ratio: 0.99431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 2372/2372 [02:10<00:00, 18.16batch/s, loss=0.0016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0021, Exact Match Ratio: 0.99552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 2372/2372 [02:12<00:00, 17.94batch/s, loss=0.000294]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0023, Exact Match Ratio: 0.99468\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "# Start a new MLflow run\n",
    "mlflow.start_run(run_name=\"jigsaw version SSL\")\n",
    "\n",
    "# Logl parameters\n",
    "mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "mlflow.log_param(\"batch_size\", train_dataloader.batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_loader_tqdm = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "    for inputs, labels in train_loader_tqdm:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # opt step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Log training loss\n",
    "    mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    exact_matches = 0  # Counter for exact matches\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute the loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate predictions\n",
    "            preds = 1*(torch.sigmoid(outputs) > 0.5)\n",
    "\n",
    "            # Check for exact matches\n",
    "            exact_matches += (preds == labels).all(dim=1).sum().item()\n",
    "\n",
    "    val_loss /= len(test_dataloader)\n",
    "    exact_match_ratio = exact_matches / len(test_dataloader.dataset)\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Exact Match Ratio: {exact_match_ratio:.5f}')\n",
    "\n",
    "    # Log validation loss and exact match ratio\n",
    "    mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "    mlflow.log_metric(\"exact_match_ratio\", exact_match_ratio, step=epoch)\n",
    "\n",
    "# Log the model\n",
    "mlflow.pytorch.log_model(model, \"jigsaw_model_same_data\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052dd485",
   "metadata": {
    "_cell_guid": "7891f781-5375-4380-a81b-caaaee795654",
    "_uuid": "789d510a-ce62-46b2-904b-01b983ba8ef9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-14T13:28:25.682021Z",
     "iopub.status.busy": "2024-06-14T13:28:25.681611Z",
     "iopub.status.idle": "2024-06-14T13:28:25.703544Z",
     "shell.execute_reply": "2024-06-14T13:28:25.702830Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.430833,
     "end_time": "2024-06-14T13:28:25.705548",
     "exception": false,
     "start_time": "2024-06-14T13:28:20.274715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), 'jigsaw_model_same_data.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5176000,
     "sourceId": 8642444,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5175452,
     "sourceId": 8646217,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 182257654,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 183370194,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 183372487,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 53503,
     "sourceId": 64167,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 53873,
     "sourceId": 64595,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 53920,
     "sourceId": 64653,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 53950,
     "sourceId": 64689,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 53999,
     "sourceId": 64742,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3401.75816,
   "end_time": "2024-06-14T13:28:33.812247",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-14T12:31:52.054087",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
