{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchsummary\n",
    "\n",
    "\n",
    "class FireStorm(nn.Module):\n",
    "    \"\"\" Firestorm module, a modified version of the Fire module from SqueezeNet\n",
    "    This model is based on Fire module from SqueezeNet with the addition of BatchNorm \n",
    "    and the change of ReLU to LeakyReLU\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): Inherited from the nn module\n",
    "\n",
    "    Returns:\n",
    "        self: Return the class instance, can be used to call the class methods\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        squeeze_planes: int,\n",
    "        expand1x1_planes: int,\n",
    "        expand3x3_planes: int,\n",
    "        \n",
    "    ) -> None:\n",
    "        \"\"\"initialization of the FireStorm module,\n",
    "        changing relatively 1x1 and 3x3 will will change the importance that the output will attribute to the two filters\n",
    "\n",
    "        Args:\n",
    "            inplanes (int): number of channels in the input tensor\n",
    "            squeeze_planes (int): number of channels in the squeeze layer, is the lowest number of channels in the module,\n",
    "            lowering this number will reduce the number of parameters in the model, but can reduce performance\n",
    "            expand1x1_planes (int): number of channels in the 1x1 convolutional layer\n",
    "            expand3x3_planes (int): number of channels in the 3x3 convolutional layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.LeakyReLU(inplace=True)\n",
    "        self.squeeze_bn = nn.BatchNorm2d(squeeze_planes)\n",
    "       \n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1)\n",
    "        self.expand1x1_activation = nn.LeakyReLU(inplace=True)\n",
    "        self.expand1x1_bn = nn.BatchNorm2d(expand1x1_planes)\n",
    "        \n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.LeakyReLU(inplace=True)\n",
    "        self.expand3x3_bn = nn.BatchNorm2d(expand3x3_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_bn(self.squeeze_activation(self.squeeze(x)))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_bn(\n",
    "                self.expand1x1_activation(self.expand1x1(x))\n",
    "            ),\n",
    "            self.expand3x3_bn(\n",
    "                self.expand3x3_activation(self.expand3x3(x)) \n",
    "            ),\n",
    "            ], 1)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "class StormColorModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This net is a custom version of SqueezeNet: we replaced the Fire module with our custom FireStorm module,\n",
    "    modified the final convolutional layer into a fully connected layer\n",
    "    we used leaky ReLU instead of ReLU\n",
    "    we added BatchNorm after each convolutional layer\n",
    "    we modified the number of fire modules and the number of filters in each fire module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 251, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "\n",
    "            FireStorm(64, 16, 64, 64),\n",
    "            FireStorm(128, 16, 64, 64),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "\n",
    "            FireStorm(128, 32, 128, 128),\n",
    "            FireStorm(256, 32, 128, 128),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "\n",
    "            FireStorm(256, 48, 192, 192),\n",
    "            FireStorm(384, 64, 256, 256),\n",
    "            \n",
    "        )\n",
    "\n",
    "class StormModel2(nn.Module):\n",
    "    \"\"\"\n",
    "    See Stormodel doc, version with more parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 251, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "\n",
    "            FireStorm(64, 16, 64, 64),\n",
    "            FireStorm(128, 16, 64, 64),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "\n",
    "            FireStorm(128, 32, 128, 128),\n",
    "            FireStorm(256, 32, 128, 128),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "\n",
    "            FireStorm(256, 48, 192, 192),\n",
    "            FireStorm(384, 64, 192, 192),\n",
    "            FireStorm(384, 64, 256, 256),  # added module\n",
    "            \n",
    "        )\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(512, self.num_classes),\n",
    "        )\n",
    "       \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 111, 111]           1,792\n",
      "         LeakyReLU-2         [-1, 64, 111, 111]               0\n",
      "         MaxPool2d-3           [-1, 64, 55, 55]               0\n",
      "            Conv2d-4           [-1, 16, 55, 55]           1,040\n",
      "         LeakyReLU-5           [-1, 16, 55, 55]               0\n",
      "       BatchNorm2d-6           [-1, 16, 55, 55]              32\n",
      "            Conv2d-7           [-1, 64, 55, 55]           1,088\n",
      "         LeakyReLU-8           [-1, 64, 55, 55]               0\n",
      "       BatchNorm2d-9           [-1, 64, 55, 55]             128\n",
      "           Conv2d-10           [-1, 64, 55, 55]           9,280\n",
      "        LeakyReLU-11           [-1, 64, 55, 55]               0\n",
      "      BatchNorm2d-12           [-1, 64, 55, 55]             128\n",
      "        FireStorm-13          [-1, 128, 55, 55]               0\n",
      "           Conv2d-14           [-1, 16, 55, 55]           2,064\n",
      "        LeakyReLU-15           [-1, 16, 55, 55]               0\n",
      "      BatchNorm2d-16           [-1, 16, 55, 55]              32\n",
      "           Conv2d-17           [-1, 64, 55, 55]           1,088\n",
      "        LeakyReLU-18           [-1, 64, 55, 55]               0\n",
      "      BatchNorm2d-19           [-1, 64, 55, 55]             128\n",
      "           Conv2d-20           [-1, 64, 55, 55]           9,280\n",
      "        LeakyReLU-21           [-1, 64, 55, 55]               0\n",
      "      BatchNorm2d-22           [-1, 64, 55, 55]             128\n",
      "        FireStorm-23          [-1, 128, 55, 55]               0\n",
      "        MaxPool2d-24          [-1, 128, 27, 27]               0\n",
      "           Conv2d-25           [-1, 32, 27, 27]           4,128\n",
      "        LeakyReLU-26           [-1, 32, 27, 27]               0\n",
      "      BatchNorm2d-27           [-1, 32, 27, 27]              64\n",
      "           Conv2d-28          [-1, 128, 27, 27]           4,224\n",
      "        LeakyReLU-29          [-1, 128, 27, 27]               0\n",
      "      BatchNorm2d-30          [-1, 128, 27, 27]             256\n",
      "           Conv2d-31          [-1, 128, 27, 27]          36,992\n",
      "        LeakyReLU-32          [-1, 128, 27, 27]               0\n",
      "      BatchNorm2d-33          [-1, 128, 27, 27]             256\n",
      "        FireStorm-34          [-1, 256, 27, 27]               0\n",
      "           Conv2d-35           [-1, 32, 27, 27]           8,224\n",
      "        LeakyReLU-36           [-1, 32, 27, 27]               0\n",
      "      BatchNorm2d-37           [-1, 32, 27, 27]              64\n",
      "           Conv2d-38          [-1, 128, 27, 27]           4,224\n",
      "        LeakyReLU-39          [-1, 128, 27, 27]               0\n",
      "      BatchNorm2d-40          [-1, 128, 27, 27]             256\n",
      "           Conv2d-41          [-1, 128, 27, 27]          36,992\n",
      "        LeakyReLU-42          [-1, 128, 27, 27]               0\n",
      "      BatchNorm2d-43          [-1, 128, 27, 27]             256\n",
      "        FireStorm-44          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-45          [-1, 256, 13, 13]               0\n",
      "           Conv2d-46           [-1, 48, 13, 13]          12,336\n",
      "        LeakyReLU-47           [-1, 48, 13, 13]               0\n",
      "      BatchNorm2d-48           [-1, 48, 13, 13]              96\n",
      "           Conv2d-49          [-1, 192, 13, 13]           9,408\n",
      "        LeakyReLU-50          [-1, 192, 13, 13]               0\n",
      "      BatchNorm2d-51          [-1, 192, 13, 13]             384\n",
      "           Conv2d-52          [-1, 192, 13, 13]          83,136\n",
      "        LeakyReLU-53          [-1, 192, 13, 13]               0\n",
      "      BatchNorm2d-54          [-1, 192, 13, 13]             384\n",
      "        FireStorm-55          [-1, 384, 13, 13]               0\n",
      "           Conv2d-56           [-1, 64, 13, 13]          24,640\n",
      "        LeakyReLU-57           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-58           [-1, 64, 13, 13]             128\n",
      "           Conv2d-59          [-1, 192, 13, 13]          12,480\n",
      "        LeakyReLU-60          [-1, 192, 13, 13]               0\n",
      "      BatchNorm2d-61          [-1, 192, 13, 13]             384\n",
      "           Conv2d-62          [-1, 192, 13, 13]         110,784\n",
      "        LeakyReLU-63          [-1, 192, 13, 13]               0\n",
      "      BatchNorm2d-64          [-1, 192, 13, 13]             384\n",
      "        FireStorm-65          [-1, 384, 13, 13]               0\n",
      "           Conv2d-66           [-1, 64, 13, 13]          24,640\n",
      "        LeakyReLU-67           [-1, 64, 13, 13]               0\n",
      "      BatchNorm2d-68           [-1, 64, 13, 13]             128\n",
      "           Conv2d-69          [-1, 256, 13, 13]          16,640\n",
      "        LeakyReLU-70          [-1, 256, 13, 13]               0\n",
      "      BatchNorm2d-71          [-1, 256, 13, 13]             512\n",
      "           Conv2d-72          [-1, 256, 13, 13]         147,712\n",
      "        LeakyReLU-73          [-1, 256, 13, 13]               0\n",
      "      BatchNorm2d-74          [-1, 256, 13, 13]             512\n",
      "        FireStorm-75          [-1, 512, 13, 13]               0\n",
      "AdaptiveAvgPool2d-76            [-1, 512, 1, 1]               0\n",
      "          Flatten-77                  [-1, 512]               0\n",
      "           Linear-78                  [-1, 512]         262,656\n",
      "        LeakyReLU-79                  [-1, 512]               0\n",
      "          Dropout-80                  [-1, 512]               0\n",
      "           Linear-81                  [-1, 251]         128,763\n",
      "================================================================\n",
      "Total params: 958,251\n",
      "Trainable params: 958,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 60.16\n",
      "Params size (MB): 3.66\n",
      "Estimated Total Size (MB): 64.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(StormModel2(), (3, 224, 224), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
